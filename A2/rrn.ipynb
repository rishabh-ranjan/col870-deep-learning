{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import r2_score, precision_score, recall_score, f1_score, confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import copy\n",
    "import torch.utils.data as torch_data\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RRN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(RRN, self).__init__()\n",
    "        \n",
    "        self.input_encoder = nn.Sequential(\n",
    "                                nn.Linear(25, 96), nn.ReLU(),\n",
    "                                nn.Linear(96, 96), nn.ReLU(),\n",
    "                                nn.Linear(96, 96), nn.ReLU(),\n",
    "                                nn.Linear(96, 16)\n",
    "                            )\n",
    "        \n",
    "        self.msg_encoder = nn.Sequential(\n",
    "                                nn.Linear(32, 96), nn.ReLU(),\n",
    "                                nn.Linear(96, 96), nn.ReLU(),\n",
    "                                nn.Linear(96, 96), nn.ReLU(),\n",
    "                                nn.Linear(96, 16)\n",
    "                            )\n",
    "        \n",
    "        self.msg_combiner = nn.Sequential(\n",
    "                                nn.Linear(32, 96), nn.ReLU(),\n",
    "                                nn.Linear(96, 96), nn.ReLU(),\n",
    "                                nn.Linear(96, 96), nn.ReLU(),\n",
    "                                nn.Linear(96, 16)\n",
    "                            )\n",
    "        \n",
    "        self.lstm_cell = nn.LSTMCell(16, 16)\n",
    "        self.decoder = nn.Linear(16, 8)\n",
    "        \n",
    "        self.adj_mask = self.generate_mask()\n",
    "    \n",
    "    def generate_mask(self):\n",
    "        mask = torch.zeros(64, 64)\n",
    "        for i in range(8):\n",
    "            for j in range(8):\n",
    "                start = 8 * i + j\n",
    "                for x in range(8):\n",
    "                    end = 8 * i + x\n",
    "                    mask[start][end] = 1\n",
    "                    end = 8 * x + j\n",
    "                    mask[start][end] = 1\n",
    "                \n",
    "                block_start_x = i // 2 * 2\n",
    "                block_start_y = j // 4 * 4\n",
    "                \n",
    "                for x in range(2):\n",
    "                    for y in range(4):\n",
    "                        X, Y = block_start_x + x, block_start_y + y\n",
    "                        end = 8 * X + Y\n",
    "                        mask[start][end] = 1\n",
    "        return mask > 0\n",
    "        \n",
    "    \n",
    "    def forward(self, h_prev, s_prev, x, m):\n",
    "        '''\n",
    "            h_prev (B, 8, 8, 16)\n",
    "            s_prev (B, 8, 8, 16)\n",
    "            x (B, 8, 8, 16)\n",
    "            m (B, 8, 8, 16)\n",
    "        '''\n",
    "        B = h_prev.shape[0]\n",
    "        xm = self.msg_combiner(torch.cat((x, m), dim=3))\n",
    "        h_next, s_next = self.lstm_cell(xm.flatten(0, 2), (h_prev.flatten(0, 2), s_prev.flatten(0, 2)))\n",
    "        \n",
    "        o = self.decoder(h_next.reshape(-1, h_next.shape[-1])) # (B * 64 * 64, 16)\n",
    "        o = o.reshape(B, 8, 8, 8) # (B, 64, 64, 16)\n",
    "        h_next, s_next = h_next.reshape(B, 8, 8, 16), s_next.reshape(B, 8, 8, 16)\n",
    "        \n",
    "        return o, h_next, s_next\n",
    "    \n",
    "    def message_passing(self, h):\n",
    "        B = h.shape[0]\n",
    "        # h (B, 8, 8, 16)\n",
    "        h_ = h.flatten(1, 2) \n",
    "        #h_ (B, 4096, 16)\n",
    "        \n",
    "        M_all = torch.cat((h_[:,:,None,:].repeat(1, 1, 64, 1), h_[:,None,:,:].repeat(1, 64, 1, 1)), dim=3)\n",
    "        M_all = M_all.flatten(1, 2)\n",
    "        # M_all (B, 4096, 32)\n",
    "        all_pairs = M_all[:,self.adj_mask.flatten(),:]\n",
    "        # (B, #constraints, 32)\n",
    "        \n",
    "        msg_pairs = self.msg_encoder(all_pairs.flatten(0, 1)).reshape(B, all_pairs.shape[1], 16)\n",
    "        # (B, #constraints, 16)\n",
    "        \n",
    "        all_msgs = torch.zeros(B, 4096, 16).cuda()\n",
    "        all_msgs[:,self.adj_mask.flatten(),:] = msg_pairs\n",
    "        \n",
    "        all_msgs = all_msgs.reshape(B, 64, 64, 16)\n",
    "        \n",
    "        return all_msgs.sum(dim=2).reshape(B, 8, 8, 16)\n",
    "    \n",
    "    def encode_input(self, sudoku):\n",
    "        # sudoku (B, 8, 8)\n",
    "        B = sudoku.shape[0]\n",
    "        col = torch.arange(0, 8, 1)\n",
    "        col = col[None,:].repeat(8, 1)[None,:,:].repeat(B, 1, 1)\n",
    "        row = col.transpose(1, 2)\n",
    "        \n",
    "        row_one_hot = F.one_hot(row, num_classes=8).cuda()\n",
    "        col_one_hot = F.one_hot(col, num_classes=8).cuda()\n",
    "        val_one_hot = F.one_hot(sudoku, num_classes=9).cuda()\n",
    "        \n",
    "        input_ = torch.cat((row_one_hot, col_one_hot, val_one_hot), dim=3)\n",
    "        #print(input_)\n",
    "        return self.input_encoder(input_.float())\n",
    "        #return input_\n",
    "    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SudokuDataset(torch_data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.query_pred = torch.tensor(torch.load('Assignment 2/visual_sudoku/query_pred.pt'))\n",
    "        self.target_pred = torch.tensor(torch.load('Assignment 2/visual_sudoku/target_pred.pt'))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.query_pred.shape[0] // 64\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        query = self.query_pred[64*i : 64*(i + 1)].reshape(8, 8)\n",
    "        target = self.target_pred[64*i : 64*(i + 1)].reshape(8, 8)\n",
    "        return query, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SudokuDataset()\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')    \n",
    "print(device)\n",
    "net = RRN().to(device)\n",
    "#net.load_state_dict(torch.load('step_32_bn.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "from tqdm.auto import tqdm\n",
    "num_epochs = 40\n",
    "num_steps = 20\n",
    "\n",
    "lmbda = lambda epoch: 0.90\n",
    "optimizer = optim.Adam(net.parameters(), lr=5e-4)\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lmbda)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "split = int(0.8 * len(dataset))\n",
    "train_data, val_data = torch.utils.data.random_split(dataset, [split, len(dataset) - split])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=256, shuffle=False)\n",
    "\n",
    "running_loss = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    print(\"Starting epoch \" + str(epoch) + \", time: \", time.time() - tic)\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        \n",
    "        \n",
    "        if i == 0:\n",
    "            net.eval()\n",
    "            with torch.no_grad():\n",
    "                total, correct = 0, 0\n",
    "                total_z, correct_z = 0, 0\n",
    "                for j, data in enumerate(val_loader):\n",
    "                    \n",
    "                    query, target = data\n",
    "                    query, target = query.to(device), target.to(device) - 1\n",
    "                    B = query.shape[0]\n",
    "                    \n",
    "                    x = net.encode_input(query)\n",
    "                    s = torch.zeros(B, 8, 8, 16).to(device)\n",
    "\n",
    "                    h = x\n",
    "                    for steps in range(num_steps):\n",
    "                        m = net.message_passing(h)\n",
    "                        o, h, s = net(h, s, x, m)\n",
    "                    del h, s\n",
    "                    \n",
    "                    pred = o.argmax(dim=3)\n",
    "                    \n",
    "                    total += query.nelement()\n",
    "                    correct += (pred == target).sum()\n",
    "                    \n",
    "                    total_z += (query == 0).sum()\n",
    "                    correct_z += ((pred == target) * (query == 0)).sum()\n",
    "                    \n",
    "                    #print(query.flatten(), \"\\n\", target.flatten(), \"\\n\", pred.flatten())\n",
    "                    \n",
    "                    #print(query.nelement(), (pred == target).sum().item(), (query == 0).sum().item(), ((pred == target) * (query == 0)).sum().item())\n",
    "                    \n",
    "                print(\"%(z):\", (correct_z.item() / total_z.item()) * 100.0,\n",
    "                     \"%(t):\", (correct.item() / total) * 100.0)\n",
    "        \n",
    "        net.train()\n",
    "        optimizer.zero_grad()\n",
    "        query, target = data\n",
    "        query, target = query.to(device), target.to(device) - 1\n",
    "        B = query.shape[0]\n",
    "        \n",
    "        x = net.encode_input(query) #B, 8, 8, 16\n",
    "        s = torch.zeros(B, 8, 8, 16).to(device)\n",
    "        h = x\n",
    "        loss = 0.0\n",
    "        for j in range(num_steps):\n",
    "            m = net.message_passing(h)\n",
    "            o, h, s = net(h, s, x, m)\n",
    "            curr_loss = criterion(o.flatten(0, 2), target.flatten(0, 2))\n",
    "            loss += curr_loss\n",
    "            #print(curr_loss.item())\n",
    "        \n",
    "        del o, h, s\n",
    "        torch.cuda.empty_cache()\n",
    "        loss = loss / num_steps\n",
    "        loss.backward()\n",
    "        #max_grad = -float('inf')\n",
    "        \n",
    "        #for param in net.named_parameters():\n",
    "        #    if param[1].grad.norm().item() > max_grad:\n",
    "        #        max_grad = max(param[1].grad.norm().item(), max_grad)\n",
    "        #        param_name = param[0]\n",
    "        #print(max_grad, param_name, loss.item())\n",
    "                \n",
    "        nn.utils.clip_grad_value_(net.parameters(), 1)\n",
    "            \n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        #print(loss.item())\n",
    "        if i % 10 == 9:\n",
    "            print(\"epoch: \", epoch + 1, \"iter: \", i + 1, \"loss: \", running_loss / 10, \"time: \", time.time() - tic)\n",
    "            running_loss = 0\n",
    "            \n",
    "    scheduler.step()\n",
    "                \n",
    "                \n",
    "            \n",
    "    running_loss = 0.0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%(z): 55.39162910292662 %(t): 77.9072265625\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    total, correct = 0, 0\n",
    "    total_z, correct_z = 0, 0\n",
    "    for j, data in enumerate(train_loader):\n",
    "\n",
    "        query, target = data\n",
    "        query, target = query.to(device), target.to(device) - 1\n",
    "        B = query.shape[0]\n",
    "\n",
    "        x = net.encode_input(query)\n",
    "        s = torch.zeros(B, 8, 8, 16).to(device)\n",
    "\n",
    "        h = x\n",
    "        for steps in range(num_steps):\n",
    "            m = net.message_passing(x)\n",
    "            o, h, s = net(h, s, x, m)\n",
    "        del h, s\n",
    "        pred = o.argmax(dim=3)\n",
    "\n",
    "        total += query.nelement()\n",
    "        correct += (pred == target).sum()\n",
    "\n",
    "        total_z += (query == 0).sum()\n",
    "        correct_z += ((pred == target) * (query == 0)).sum()\n",
    "\n",
    "    print(\"%(z):\", (correct_z.item() / total_z.item()) * 100.0,\n",
    "         \"%(t):\", (correct.item() / total) * 100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512000 0.493873046875\n",
      "[34, 25, 24, 29, 34, 27, 38, 36, 29, 24, 29, 35, 38, 27, 37, 27, 33, 24, 23, 29, 36, 29, 26, 36, 39, 25, 31, 40, 29, 32, 25, 38, 38, 24, 27, 27, 40, 25, 38, 34, 35, 35, 37, 33, 32, 33, 25, 26, 25, 36, 38, 34, 31, 39, 36, 40, 31, 26, 29, 26, 39, 22, 34, 37, 31, 27, 27, 40, 40, 35, 32, 37, 33, 39, 30, 28, 29, 32, 37, 39, 29, 32, 34, 24, 26, 34, 26, 28, 35, 38, 27, 31, 36, 33, 31, 35, 36, 33, 35, 39]\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "total = 0\n",
    "givens = []\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=1, shuffle=False)\n",
    "\n",
    "for j, data in enumerate(train_loader):\n",
    "    q, t = data\n",
    "    total += t.nelement()\n",
    "    count += t.nelement() - (t == q).sum()\n",
    "    givens.append((t == q).sum().item())\n",
    "\n",
    "print(total, count.item() / total)\n",
    "print(givens[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0, 4, 0, 2, 3],\n",
      "        [0, 0, 6, 0, 7, 0, 0, 5],\n",
      "        [8, 0, 1, 6, 0, 7, 0, 0],\n",
      "        [0, 0, 5, 0, 0, 0, 6, 0],\n",
      "        [0, 0, 7, 3, 0, 0, 0, 0],\n",
      "        [4, 1, 0, 0, 6, 5, 3, 7],\n",
      "        [1, 6, 0, 0, 0, 2, 7, 4],\n",
      "        [2, 0, 4, 7, 5, 3, 1, 6]])\n",
      "tensor(32, device='cuda:0')\n",
      "0\n",
      "tensor(53, device='cuda:0')\n",
      "1\n",
      "tensor(53, device='cuda:0')\n",
      "2\n",
      "tensor(53, device='cuda:0')\n",
      "3\n",
      "tensor(53, device='cuda:0')\n",
      "4\n",
      "tensor(53, device='cuda:0')\n",
      "5\n",
      "tensor(53, device='cuda:0')\n",
      "6\n",
      "tensor(53, device='cuda:0')\n",
      "7\n",
      "tensor(54, device='cuda:0')\n",
      "8\n",
      "tensor(54, device='cuda:0')\n",
      "9\n",
      "tensor(54, device='cuda:0')\n",
      "10\n",
      "tensor(54, device='cuda:0')\n",
      "11\n",
      "tensor(54, device='cuda:0')\n",
      "12\n",
      "tensor(54, device='cuda:0')\n",
      "13\n",
      "tensor(54, device='cuda:0')\n",
      "14\n",
      "tensor(54, device='cuda:0')\n",
      "15\n",
      "tensor(54, device='cuda:0')\n",
      "16\n",
      "tensor(54, device='cuda:0')\n",
      "17\n",
      "tensor(54, device='cuda:0')\n",
      "18\n",
      "tensor(53, device='cuda:0')\n",
      "19\n",
      "tensor(53, device='cuda:0')\n",
      "20\n",
      "tensor(53, device='cuda:0')\n",
      "21\n",
      "tensor(53, device='cuda:0')\n",
      "22\n",
      "tensor(53, device='cuda:0')\n",
      "23\n",
      "tensor(53, device='cuda:0')\n",
      "24\n",
      "tensor(53, device='cuda:0')\n",
      "25\n",
      "tensor(53, device='cuda:0')\n",
      "26\n",
      "tensor(53, device='cuda:0')\n",
      "27\n",
      "tensor(53, device='cuda:0')\n",
      "28\n",
      "tensor(53, device='cuda:0')\n",
      "29\n",
      "tensor(53, device='cuda:0')\n",
      "30\n",
      "tensor(53, device='cuda:0')\n",
      "31\n",
      "tensor(53, device='cuda:0')\n",
      "tensor([[[7, 7, 8, 5, 4, 6, 2, 3],\n",
      "         [3, 2, 6, 1, 7, 1, 8, 5],\n",
      "         [8, 2, 1, 6, 3, 7, 5, 2],\n",
      "         [7, 7, 5, 2, 1, 1, 6, 1],\n",
      "         [6, 5, 7, 3, 1, 1, 4, 1],\n",
      "         [4, 1, 2, 2, 6, 5, 3, 7],\n",
      "         [1, 6, 3, 8, 8, 2, 7, 4],\n",
      "         [2, 8, 4, 7, 5, 3, 1, 6]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "idx = 20\n",
    "print(train_data.__getitem__(idx)[0])\n",
    "x = net.encode_input(train_data.__getitem__(idx)[0].unsqueeze(0).cuda())\n",
    "s = torch.zeros(1, 8, 8, 16).to(device)\n",
    "\n",
    "\n",
    "output = train_data.__getitem__(idx)[1].unsqueeze(0).cuda()\n",
    "num_steps = 32\n",
    "h = x\n",
    "print(64 - (train_data.__getitem__(idx)[0].unsqueeze(0).cuda() == 0).sum())\n",
    "\n",
    "for steps in range(num_steps):\n",
    "    m = net.message_passing(x)\n",
    "    o, h, s = net(h, s, x, m)\n",
    "    #print((o.argmax(dim=3) + 1).cpu().float() * mask.cpu().float())\n",
    "    print(steps)\n",
    "    print(((o.argmax(dim=3) + 1) == output).sum())\n",
    "del h, s\n",
    "pred = o.argmax(dim=3)\n",
    "print(pred + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')    \n",
    "net = RRN().to(device)\n",
    "net.load_state_dict(torch.load('step_25_correct.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(18)\n",
      "tensor([[[4, 6, 8, 2, 1, 5, 3, 7],\n",
      "         [3, 1, 5, 1, 6, 2, 4, 8],\n",
      "         [6, 3, 1, 8, 5, 7, 2, 4],\n",
      "         [7, 4, 2, 8, 8, 6, 2, 3],\n",
      "         [8, 2, 6, 7, 3, 4, 7, 1],\n",
      "         [8, 1, 4, 3, 7, 8, 6, 2],\n",
      "         [1, 5, 7, 4, 2, 3, 8, 6],\n",
      "         [2, 8, 3, 6, 4, 1, 7, 5]]], device='cuda:0')\n",
      "True\n",
      "0.05385398864746094\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "net.eval()\n",
    "\n",
    "sudoku = torch.tensor([[\n",
    "    [4, 0, 0, 2, 1, 0, 0, 7], \n",
    "    [0, 0, 5, 0, 6, 0, 0, 0], \n",
    "    [0, 3, 0, 0, 0, 0, 7, 0], \n",
    "    [0, 4, 0, 0, 0, 6, 0, 0],\n",
    "    [0, 0, 0, 0, 3, 4, 0, 1],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 2],\n",
    "    [1, 0, 0, 4, 0, 0, 8, 0],\n",
    "    [2, 0, 0, 0, 0, 0, 0, 5]\n",
    "]])\n",
    "\n",
    "tic = time.time()\n",
    "print(64 - (sudoku == 0).sum())\n",
    "x = net.encode_input(sudoku)\n",
    "s = torch.zeros(1, 8, 8, 16).to(device)\n",
    "\n",
    "h = x\n",
    "for steps in range(25):\n",
    "    m = net.message_passing(h)\n",
    "    o, h, s = net(h, s, x, m)\n",
    "del h, s\n",
    "\n",
    "pred = o.argmax(dim=3) + 1\n",
    "toc = time.time()\n",
    "print(pred)\n",
    "print(constraint_violation(pred.squeeze()))\n",
    "print(toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constraint_violation(sudoku):\n",
    "    for i in range(8):\n",
    "        a = set()\n",
    "        for j in range(8):\n",
    "            elem = sudoku[i][j].item()\n",
    "            a.add(elem)\n",
    "        #print(\"row\", a)\n",
    "        if not len(a) == 8:\n",
    "            return True\n",
    "        \n",
    "    for i in range(8):\n",
    "        a = set()\n",
    "        for j in range(8):\n",
    "            elem = sudoku[j][i].item()\n",
    "            a.add(elem)\n",
    "        #print(\"col\", a)\n",
    "        if not len(a) == 8:\n",
    "            return True\n",
    "    \n",
    "    for i in range(0, 8, 2):\n",
    "        for j in range(0, 8, 4):\n",
    "            a = set()\n",
    "            for x in range(0, 2):\n",
    "                for y in range(0, 4):\n",
    "                    elem = sudoku[i + x][j + y].item()\n",
    "                    a.add(elem)\n",
    "            #print(\"block\", a)      \n",
    "            if not len(a) == 8:\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
