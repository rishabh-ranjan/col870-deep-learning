{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, n=2, r=10):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.n = n\n",
    "        self.r = r\n",
    "        \n",
    "        self.red0 = nn.Conv2d(3, 16, kernel_size=1, stride=1)\n",
    "        l1 = []\n",
    "        for i in range(2 * n):\n",
    "            if i == 0:\n",
    "                l1.append(nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1))\n",
    "            else:\n",
    "                l1.append(nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1))\n",
    "        self.l1 = nn.ModuleList(l1)\n",
    "        \n",
    "        self.red1 = nn.Conv2d(16, 32, kernel_size=1, stride=2)\n",
    "        \n",
    "        l2 = []\n",
    "        for i in range(2 * n):\n",
    "            if i == 0:\n",
    "                l2.append(nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1))\n",
    "            else:\n",
    "                l2.append(nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1))\n",
    "        \n",
    "        self.l2 = nn.ModuleList(l2)\n",
    "        \n",
    "        self.red2 = nn.Conv2d(32, 64, kernel_size=1, stride=2)\n",
    "        l3 = []\n",
    "        for i in range(2 * n):\n",
    "            if i == 0:\n",
    "                l3.append(nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1))\n",
    "            else:\n",
    "                l3.append(nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1))\n",
    "        \n",
    "        self.l3 = nn.ModuleList(l3)\n",
    "        self.fc = nn.Linear(4096, 10)\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, X):\n",
    "        \n",
    "        i1 = [X]\n",
    "        z1 = [None]\n",
    "        o1 = [None]\n",
    "        \n",
    "        for i in range(1, self.n * 2 + 1):\n",
    "            z = self.l1[i - 1](i1[i - 1])\n",
    "            z1.append(z)\n",
    "            o1.append(F.relu(z))\n",
    "            \n",
    "            if i % 2 == 0:\n",
    "                if i == 2:\n",
    "                    i1.append(o1[i] + self.red0(i1[i - 2]))\n",
    "                else:\n",
    "                    i1.append(o1[i] + i1[i - 2])\n",
    "            else:\n",
    "                i1.append(o1[i])\n",
    "        \n",
    "        \n",
    "        i2 = [o1[self.n * 2]]\n",
    "        z2 = [None]\n",
    "        o2 = [None]\n",
    "        \n",
    "        for i in range(1, self.n * 2 + 1):\n",
    "            z = self.l2[i - 1](i2[i - 1])\n",
    "            z2.append(z)\n",
    "            o2.append(F.relu(z))\n",
    "            \n",
    "            if i % 2 == 0:\n",
    "                if i == 2:\n",
    "                    i2.append(o2[i] + self.red1(i2[i - 2]))\n",
    "                else:\n",
    "                    i2.append(o2[i] + i2[i - 2])\n",
    "            else:\n",
    "                i2.append(o2[i])\n",
    "                    \n",
    "        \n",
    "        i3 = [o2[self.n * 2]]\n",
    "        z3 = [None]\n",
    "        o3 = [None]\n",
    "        \n",
    "        for i in range(1, self.n * 2 + 1):\n",
    "            z = self.l3[i - 1](i3[i - 1])\n",
    "            z3.append(z)\n",
    "            o3.append(F.relu(z))\n",
    "            \n",
    "            if i % 2 == 0:\n",
    "                if i == 2:\n",
    "                    i3.append(o3[i] + self.red2(i3[i - 2]))\n",
    "                else:\n",
    "                    i3.append(o3[i] + i3[i - 2])\n",
    "            else:\n",
    "                i3.append(o3[i])\n",
    "        \n",
    "        output = i3[self.n * 2].flatten(1)\n",
    "        output = self.fc(output)\n",
    "        #print(output)\n",
    "        return F.softmax(output, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='/home/cse/dual/cs5180404/scratch/col870/', train=True, transform=transform)\n",
    "print(len(trainset))\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "net = ResNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    50] loss: 0.040466\n",
      "[1,   100] loss: 0.041181\n",
      "[1,   150] loss: 0.041827\n",
      "[1,   200] loss: 0.040790\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=3e-6)\n",
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        #print(inputs.shape)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        #print(outputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        #print(loss.item())\n",
    "        if i % 50 == 49:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "0.8227947172270248\n",
      "[[4298   68  101   77   54   21   23   57  179  122]\n",
      " [  38 4577   23   28   18   17   34   18   66  181]\n",
      " [ 230   37 3574  241  252  192  248  100   74   52]\n",
      " [  79   23  224 3583  192  436  221  131   50   61]\n",
      " [ 108   21  183  189 3928  142  156  200   35   38]\n",
      " [  34   22  175  505  206 3647  124  194   25   68]\n",
      " [  33   32  147  164  113   86 4353   26   20   26]\n",
      " [  41   20  105  157  164  168   34 4247   15   49]\n",
      " [ 136   79   50   46   27   19   20    7 4554   62]\n",
      " [  96  214   25   57   34   28   28   43   60 4415]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='/home/cse/dual/cs5180404/scratch/col870/', train=True, transform=transform)\n",
    "print(len(testset))\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "actual, prediction = [], []\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    inputs, labels = data\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    #print(inputs.shape)\n",
    "    actual.extend(labels.squeeze().tolist())\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    output = net(inputs)\n",
    "    \n",
    "    prediction.extend(torch.argmax(output, dim=1).squeeze().tolist())\n",
    "    #print(output)\n",
    "print(f1_score(actual, prediction, average='macro'))\n",
    "print(confusion_matrix(actual, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
