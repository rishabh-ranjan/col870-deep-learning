===============================
2325594.pbshpc
khas092.hpc.iitd.ac.in
===============================
['B-art', 'B-eve', 'B-geo', 'B-gpe', 'B-nat', 'B-org', 'B-per', 'B-tim', 'I-art', 'I-eve', 'I-geo', 'I-gpe', 'I-nat', 'I-org', 'I-per', 'I-tim', 'O', 'PAD_LBL', 'START_LBL'] {'B-art': 0, 'B-eve': 1, 'B-geo': 2, 'B-gpe': 3, 'B-nat': 4, 'B-org': 5, 'B-per': 6, 'B-tim': 7, 'I-art': 8, 'I-eve': 9, 'I-geo': 10, 'I-gpe': 11, 'I-nat': 12, 'I-org': 13, 'I-per': 14, 'I-tim': 15, 'O': 16, 'PAD_LBL': 17, 'START_LBL': 18}
initializing self.T
LinearCRF(
  (lstm): NERModel(
    (embed_model): ChrTokEmbModel(
      (chr_emb_model): ChrEmbModel(
        (embedding): Embedding(95, 16, padding_idx=93)
        (lstm): LSTM(16, 25, batch_first=True, bidirectional=True)
      )
      (tok_emb_model): TokEmbModel(
        (embedding): Embedding(400002, 100, padding_idx=400000)
      )
    )
    (seq_tag_model): SeqTagModel(
      (dropout): Dropout(p=0.5)
      (lstm): LSTM(150, 100, batch_first=True, bidirectional=True)
      (linear): Linear(in_features=200, out_features=19, bias=True)
    )
    (cross_entropy_loss): CrossEntropyLoss()
  )
  (dropout): Dropout(p=0.5)
  (proj): Sequential(
    (0): Linear(in_features=200, out_features=100, bias=True)
    (1): ReLU()
    (2): Linear(in_features=100, out_features=19, bias=True)
  )
)
[1,    10] loss: 30.425605
[1,    20] loss: 27.322910
[1,    30] loss: 25.987696
[1,    40] loss: 23.796642
[1,    50] loss: 21.018224
[1,    60] loss: 19.391588
[1,    70] loss: 18.765514
[1,    80] loss: 18.127942
[1,    90] loss: 16.793899
[1,   100] loss: 16.708312
[1,   110] loss: 15.065318
[1,   120] loss: 13.323407
[1,   130] loss: 12.905631
[1,   140] loss: 11.129220
[1,   150] loss: 10.790180
[1,   160] loss: 10.389295
[1,   170] loss: 9.317905
[1,   180] loss: 9.335708
[1,   190] loss: 9.282965
[1,   200] loss: 9.044138
[1,   210] loss: 8.247608
[1,   220] loss: 8.615296
[1,   230] loss: 7.965731
[1,   240] loss: 8.277499
[1,   250] loss: 7.376581
[1,   260] loss: 7.194610
[1,   270] loss: 7.308859
[1,   280] loss: 7.215209
[1,   290] loss: 6.987473
val loss: 5.674614726526278
best loss: inf
Patience: 15
time: 90.00558519363403
[2,    10] loss: 6.933600
[2,    20] loss: 6.978505
[2,    30] loss: 6.287452
[2,    40] loss: 6.697396
[2,    50] loss: 6.666573
[2,    60] loss: 6.166429
[2,    70] loss: 6.026950
[2,    80] loss: 6.050314
[2,    90] loss: 6.362381
[2,   100] loss: 6.489735
[2,   110] loss: 6.052335
[2,   120] loss: 6.146524
[2,   130] loss: 5.725515
[2,   140] loss: 5.432138
[2,   150] loss: 5.691985
[2,   160] loss: 5.369585
[2,   170] loss: 5.298511
[2,   180] loss: 5.936591
[2,   190] loss: 5.664923
[2,   200] loss: 5.503001
[2,   210] loss: 5.706453
[2,   220] loss: 5.453975
[2,   230] loss: 5.110540
[2,   240] loss: 5.740932
[2,   250] loss: 5.592979
[2,   260] loss: 5.434381
[2,   270] loss: 5.313315
[2,   280] loss: 4.943964
[2,   290] loss: 4.967159
val loss: 4.172647021889898
best loss: 5.674614726526278
Patience: 15
time: 180.12936305999756
[3,    10] loss: 4.813374
[3,    20] loss: 4.778012
[3,    30] loss: 4.848718
[3,    40] loss: 4.903154
[3,    50] loss: 5.063214
[3,    60] loss: 5.030695
[3,    70] loss: 4.958788
[3,    80] loss: 4.817498
[3,    90] loss: 4.791338
[3,   100] loss: 4.566728
[3,   110] loss: 4.542109
[3,   120] loss: 4.630248
[3,   130] loss: 4.711037
[3,   140] loss: 4.704282
[3,   150] loss: 4.350683
[3,   160] loss: 4.534773
[3,   170] loss: 4.627097
[3,   180] loss: 4.337673
[3,   190] loss: 4.495834
[3,   200] loss: 4.436890
[3,   210] loss: 4.239603
[3,   220] loss: 4.391995
[3,   230] loss: 4.212395
[3,   240] loss: 4.591228
[3,   250] loss: 4.413518
[3,   260] loss: 4.371467
[3,   270] loss: 4.300326
[3,   280] loss: 4.273606
[3,   290] loss: 4.386518
val loss: 3.5912886497917107
best loss: 4.172647021889898
Patience: 15
time: 270.3163375854492
[4,    10] loss: 4.015528
[4,    20] loss: 4.325054
[4,    30] loss: 4.036189
[4,    40] loss: 4.386954
[4,    50] loss: 4.038699
[4,    60] loss: 3.960267
[4,    70] loss: 4.235409
[4,    80] loss: 3.882716
[4,    90] loss: 3.831158
[4,   100] loss: 3.758629
[4,   110] loss: 4.369648
[4,   120] loss: 3.978491
[4,   130] loss: 4.072548
[4,   140] loss: 3.942738
[4,   150] loss: 3.544311
[4,   160] loss: 3.735055
[4,   170] loss: 3.961882
[4,   180] loss: 3.530844
[4,   190] loss: 3.879801
[4,   200] loss: 4.078676
[4,   210] loss: 3.944090
[4,   220] loss: 3.675929
[4,   230] loss: 3.588178
[4,   240] loss: 3.984570
[4,   250] loss: 3.858365
[4,   260] loss: 3.972800
[4,   270] loss: 3.602839
[4,   280] loss: 3.320385
[4,   290] loss: 3.763163
val loss: 3.230148689455802
best loss: 3.5912886497917107
Patience: 15
time: 360.4915626049042
[5,    10] loss: 3.713097
[5,    20] loss: 3.516557
[5,    30] loss: 3.717095
[5,    40] loss: 3.571949
[5,    50] loss: 3.486810
[5,    60] loss: 3.667223
[5,    70] loss: 3.640802
[5,    80] loss: 3.632353
[5,    90] loss: 3.726587
[5,   100] loss: 3.453740
[5,   110] loss: 3.575842
[5,   120] loss: 3.238242
[5,   130] loss: 3.410089
[5,   140] loss: 3.738529
[5,   150] loss: 3.295038
[5,   160] loss: 3.206368
[5,   170] loss: 3.189997
[5,   180] loss: 3.358556
[5,   190] loss: 3.254295
[5,   200] loss: 3.627810
[5,   210] loss: 3.535953
[5,   220] loss: 3.145496
[5,   230] loss: 3.327046
[5,   240] loss: 3.241377
[5,   250] loss: 3.258572
[5,   260] loss: 3.109725
[5,   270] loss: 3.367806
[5,   280] loss: 3.126183
[5,   290] loss: 3.239531
val loss: 2.9387529284276224
best loss: 3.230148689455802
Patience: 15
time: 450.56787061691284
[6,    10] loss: 3.084029
[6,    20] loss: 3.285336
[6,    30] loss: 3.043166
[6,    40] loss: 3.305265
[6,    50] loss: 3.345029
[6,    60] loss: 3.012466
[6,    70] loss: 3.126175
[6,    80] loss: 2.951628
[6,    90] loss: 3.262525
[6,   100] loss: 3.049384
[6,   110] loss: 3.239728
[6,   120] loss: 3.294447
[6,   130] loss: 3.075684
[6,   140] loss: 2.864507
[6,   150] loss: 2.880935
[6,   160] loss: 3.008896
[6,   170] loss: 2.702397
[6,   180] loss: 3.199315
[6,   190] loss: 3.018313
[6,   200] loss: 3.207601
[6,   210] loss: 3.099113
[6,   220] loss: 3.194344
[6,   230] loss: 3.035721
[6,   240] loss: 2.996165
[6,   250] loss: 3.073095
[6,   260] loss: 3.075616
[6,   270] loss: 3.006718
[6,   280] loss: 3.041873
[6,   290] loss: 3.067639
val loss: 2.7449093753917433
best loss: 2.9387529284276224
Patience: 15
time: 540.8131504058838
[7,    10] loss: 3.088603
[7,    20] loss: 2.863711
[7,    30] loss: 2.984043
[7,    40] loss: 2.794987
[7,    50] loss: 2.828601
[7,    60] loss: 2.751970
[7,    70] loss: 2.977011
[7,    80] loss: 2.768254
[7,    90] loss: 2.706725
[7,   100] loss: 2.798502
[7,   110] loss: 2.691037
[7,   120] loss: 2.722974
[7,   130] loss: 2.582974
[7,   140] loss: 2.986111
[7,   150] loss: 2.782352
[7,   160] loss: 2.795432
[7,   170] loss: 2.797316
[7,   180] loss: 2.720734
[7,   190] loss: 2.798714
[7,   200] loss: 2.803489
[7,   210] loss: 2.617231
[7,   220] loss: 3.041083
[7,   230] loss: 2.864329
[7,   240] loss: 2.655021
[7,   250] loss: 2.817934
[7,   260] loss: 2.550396
[7,   270] loss: 2.575235
[7,   280] loss: 2.924742
[7,   290] loss: 2.934677
val loss: 2.573586578196892
best loss: 2.7449093753917433
Patience: 15
time: 630.9051518440247
[8,    10] loss: 2.504738
[8,    20] loss: 2.592151
[8,    30] loss: 2.679731
[8,    40] loss: 2.583364
[8,    50] loss: 2.558228
[8,    60] loss: 2.599243
[8,    70] loss: 2.630627
[8,    80] loss: 2.698920
[8,    90] loss: 2.538033
[8,   100] loss: 2.632858
[8,   110] loss: 2.675039
[8,   120] loss: 2.664508
[8,   130] loss: 2.625220
[8,   140] loss: 2.607819
[8,   150] loss: 2.652903
[8,   160] loss: 2.646233
[8,   170] loss: 2.642831
[8,   180] loss: 2.511141
[8,   190] loss: 2.488103
[8,   200] loss: 2.515970
[8,   210] loss: 2.578788
[8,   220] loss: 2.522425
[8,   230] loss: 2.578117
[8,   240] loss: 2.500392
[8,   250] loss: 2.528103
[8,   260] loss: 2.647551
[8,   270] loss: 2.447334
[8,   280] loss: 2.508966
[8,   290] loss: 2.461360
val loss: 2.460584744159838
best loss: 2.573586578196892
Patience: 15
time: 720.9909546375275
[9,    10] loss: 2.562852
[9,    20] loss: 2.570473
[9,    30] loss: 2.412302
[9,    40] loss: 2.358114
[9,    50] loss: 2.267085
[9,    60] loss: 2.331444
[9,    70] loss: 2.546120
[9,    80] loss: 2.343091
[9,    90] loss: 2.374324
[9,   100] loss: 2.361152
[9,   110] loss: 2.521768
[9,   120] loss: 2.434910
[9,   130] loss: 2.347137
[9,   140] loss: 2.286416
[9,   150] loss: 2.406414
[9,   160] loss: 2.588994
[9,   170] loss: 2.383339
[9,   180] loss: 2.513050
[9,   190] loss: 2.413532
[9,   200] loss: 2.472142
[9,   210] loss: 2.286740
[9,   220] loss: 2.522894
[9,   230] loss: 2.583609
[9,   240] loss: 2.190300
[9,   250] loss: 2.237124
[9,   260] loss: 2.346656
[9,   270] loss: 2.419074
[9,   280] loss: 2.324667
[9,   290] loss: 2.284799
val loss: 2.3257390960265196
best loss: 2.460584744159838
Patience: 15
time: 811.1873052120209
[10,    10] loss: 2.262847
[10,    20] loss: 2.285208
[10,    30] loss: 2.244325
[10,    40] loss: 2.453634
[10,    50] loss: 2.118305
[10,    60] loss: 2.266761
[10,    70] loss: 2.310942
[10,    80] loss: 2.339219
[10,    90] loss: 2.265076
[10,   100] loss: 2.196019
[10,   110] loss: 2.328268
[10,   120] loss: 2.260481
[10,   130] loss: 2.253476
[10,   140] loss: 2.096274
[10,   150] loss: 2.236188
[10,   160] loss: 2.292904
[10,   170] loss: 2.187457
[10,   180] loss: 2.268527
[10,   190] loss: 2.357203
[10,   200] loss: 2.185399
[10,   210] loss: 2.159998
[10,   220] loss: 1.996863
[10,   230] loss: 2.063110
[10,   240] loss: 2.195480
[10,   250] loss: 2.213457
[10,   260] loss: 2.341723
[10,   270] loss: 2.112060
[10,   280] loss: 2.182474
[10,   290] loss: 2.310318
val loss: 2.267018330941141
best loss: 2.3257390960265196
Patience: 15
time: 901.2212543487549
[11,    10] loss: 2.212885
[11,    20] loss: 2.163337
[11,    30] loss: 2.015111
[11,    40] loss: 2.122602
[11,    50] loss: 1.909145
[11,    60] loss: 2.247239
[11,    70] loss: 2.098379
[11,    80] loss: 2.154159
[11,    90] loss: 2.048564
[11,   100] loss: 2.234016
[11,   110] loss: 2.144375
[11,   120] loss: 2.061248
[11,   130] loss: 2.069797
[11,   140] loss: 2.121338
[11,   150] loss: 2.196115
[11,   160] loss: 1.953819
[11,   170] loss: 2.250192
[11,   180] loss: 2.094339
[11,   190] loss: 2.119803
[11,   200] loss: 1.927920
[11,   210] loss: 2.077629
[11,   220] loss: 2.127607
[11,   230] loss: 2.156653
[11,   240] loss: 2.036407
[11,   250] loss: 2.098383
[11,   260] loss: 2.008934
[11,   270] loss: 2.177421
[11,   280] loss: 2.146792
[11,   290] loss: 2.085153
val loss: 2.1619791720802026
best loss: 2.267018330941141
Patience: 15
time: 991.201188325882
[12,    10] loss: 2.108467
[12,    20] loss: 1.894793
[12,    30] loss: 1.967384
[12,    40] loss: 1.882067
[12,    50] loss: 2.038123
[12,    60] loss: 1.923428
[12,    70] loss: 2.110087
[12,    80] loss: 2.091373
[12,    90] loss: 1.809803
[12,   100] loss: 2.050913
[12,   110] loss: 1.894792
[12,   120] loss: 2.035873
[12,   130] loss: 2.042317
[12,   140] loss: 1.982892
[12,   150] loss: 1.910527
[12,   160] loss: 1.932990
[12,   170] loss: 2.074895
[12,   180] loss: 1.955610
[12,   190] loss: 1.980402
[12,   200] loss: 2.222762
[12,   210] loss: 1.980200
[12,   220] loss: 2.046764
[12,   230] loss: 1.917149
[12,   240] loss: 1.869191
[12,   250] loss: 1.951828
[12,   260] loss: 2.165912
[12,   270] loss: 1.835833
[12,   280] loss: 1.886159
[12,   290] loss: 2.135211
val loss: 2.095002698352348
best loss: 2.1619791720802026
Patience: 15
time: 1081.269299030304
===============================
2325611.pbshpc
khas092.hpc.iitd.ac.in
===============================
['B-art', 'B-eve', 'B-geo', 'B-gpe', 'B-nat', 'B-org', 'B-per', 'B-tim', 'I-art', 'I-eve', 'I-geo', 'I-gpe', 'I-nat', 'I-org', 'I-per', 'I-tim', 'O', 'PAD_LBL', 'START_LBL'] {'B-art': 0, 'B-eve': 1, 'B-geo': 2, 'B-gpe': 3, 'B-nat': 4, 'B-org': 5, 'B-per': 6, 'B-tim': 7, 'I-art': 8, 'I-eve': 9, 'I-geo': 10, 'I-gpe': 11, 'I-nat': 12, 'I-org': 13, 'I-per': 14, 'I-tim': 15, 'O': 16, 'PAD_LBL': 17, 'START_LBL': 18}
initializing self.T
===============================
2325618.pbshpc
khas151.hpc.iitd.ac.in
===============================
['B-art', 'B-eve', 'B-geo', 'B-gpe', 'B-nat', 'B-org', 'B-per', 'B-tim', 'I-art', 'I-eve', 'I-geo', 'I-gpe', 'I-nat', 'I-org', 'I-per', 'I-tim', 'O', 'PAD_LBL', 'START_LBL'] {'B-art': 0, 'B-eve': 1, 'B-geo': 2, 'B-gpe': 3, 'B-nat': 4, 'B-org': 5, 'B-per': 6, 'B-tim': 7, 'I-art': 8, 'I-eve': 9, 'I-geo': 10, 'I-gpe': 11, 'I-nat': 12, 'I-org': 13, 'I-per': 14, 'I-tim': 15, 'O': 16, 'PAD_LBL': 17, 'START_LBL': 18}
initializing self.T
===============================
2325633.pbshpc
khas151.hpc.iitd.ac.in
===============================
['B-art', 'B-eve', 'B-geo', 'B-gpe', 'B-nat', 'B-org', 'B-per', 'B-tim', 'I-art', 'I-eve', 'I-geo', 'I-gpe', 'I-nat', 'I-org', 'I-per', 'I-tim', 'O', 'PAD_LBL', 'START_LBL'] {'B-art': 0, 'B-eve': 1, 'B-geo': 2, 'B-gpe': 3, 'B-nat': 4, 'B-org': 5, 'B-per': 6, 'B-tim': 7, 'I-art': 8, 'I-eve': 9, 'I-geo': 10, 'I-gpe': 11, 'I-nat': 12, 'I-org': 13, 'I-per': 14, 'I-tim': 15, 'O': 16, 'PAD_LBL': 17, 'START_LBL': 18}
initializing self.T
LinearCRF(
  (lstm): NERModel(
    (embed_model): ChrTokEmbModel(
      (chr_emb_model): ChrEmbModel(
        (embedding): Embedding(95, 16, padding_idx=93)
        (lstm): LSTM(16, 25, batch_first=True, bidirectional=True)
      )
      (tok_emb_model): TokEmbModel(
        (embedding): Embedding(400002, 100, padding_idx=400000)
      )
    )
    (seq_tag_model): SeqTagModel(
      (dropout): Dropout(p=0.5)
      (lstm): LSTM(150, 100, batch_first=True, bidirectional=True)
      (linear): Linear(in_features=200, out_features=19, bias=True)
    )
    (cross_entropy_loss): CrossEntropyLoss()
  )
  (dropout): Dropout(p=0.5)
  (proj): Sequential(
    (0): Linear(in_features=200, out_features=100, bias=True)
    (1): ReLU()
    (2): Linear(in_features=100, out_features=19, bias=True)
  )
)
[1,    10] loss: 13.001052
[1,    20] loss: 11.503576
[1,    30] loss: 10.007080
[1,    40] loss: 8.466235
[1,    50] loss: 7.312380
[1,    60] loss: 6.535700
[1,    70] loss: 5.703649
[1,    80] loss: 5.447959
[1,    90] loss: 4.956029
[1,   100] loss: 4.897953
[1,   110] loss: 4.618822
[1,   120] loss: 4.425762
[1,   130] loss: 4.309962
[1,   140] loss: 4.259148
[1,   150] loss: 4.223372
[1,   160] loss: 3.938529
[1,   170] loss: 4.010195
[1,   180] loss: 3.909783
[1,   190] loss: 3.701148
[1,   200] loss: 3.635569
[1,   210] loss: 3.731576
[1,   220] loss: 3.623491
[1,   230] loss: 3.490363
[1,   240] loss: 3.364956
[1,   250] loss: 3.224201
[1,   260] loss: 3.320291
[1,   270] loss: 3.394097
[1,   280] loss: 3.327794
[1,   290] loss: 3.273059
val loss: 2.548328643882492
best loss: inf
Patience: 15
time: 86.41691327095032
[2,    10] loss: 3.278903
[2,    20] loss: 3.106409
[2,    30] loss: 3.044863
[2,    40] loss: 3.009223
[2,    50] loss: 3.112410
[2,    60] loss: 2.935351
[2,    70] loss: 2.869183
[2,    80] loss: 2.885072
[2,    90] loss: 2.840301
[2,   100] loss: 2.968078
[2,   110] loss: 2.810547
[2,   120] loss: 2.831946
[2,   130] loss: 2.906800
[2,   140] loss: 2.913454
[2,   150] loss: 2.601366
[2,   160] loss: 2.783154
[2,   170] loss: 2.591123
[2,   180] loss: 2.787004
[2,   190] loss: 2.716904
[2,   200] loss: 2.766425
[2,   210] loss: 2.670028
[2,   220] loss: 2.713038
[2,   230] loss: 2.677246
[2,   240] loss: 2.465294
[2,   250] loss: 2.780315
[2,   260] loss: 2.560170
[2,   270] loss: 2.762034
[2,   280] loss: 2.551795
[2,   290] loss: 2.586542
val loss: 2.0917013617719955
best loss: 2.548328643882492
Patience: 15
time: 173.35169982910156
[3,    10] loss: 2.586575
[3,    20] loss: 2.539852
[3,    30] loss: 2.561674
[3,    40] loss: 2.548562
[3,    50] loss: 2.488558
[3,    60] loss: 2.499530
[3,    70] loss: 2.372871
[3,    80] loss: 2.388798
[3,    90] loss: 2.392200
[3,   100] loss: 2.375927
[3,   110] loss: 2.271661
[3,   120] loss: 2.383386
[3,   130] loss: 2.554316
[3,   140] loss: 2.301613
[3,   150] loss: 2.340774
[3,   160] loss: 2.380042
[3,   170] loss: 2.347451
[3,   180] loss: 2.264288
[3,   190] loss: 2.240910
[3,   200] loss: 2.355652
[3,   210] loss: 2.266706
[3,   220] loss: 2.415273
[3,   230] loss: 2.300614
[3,   240] loss: 2.266106
[3,   250] loss: 2.296388
[3,   260] loss: 2.231985
[3,   270] loss: 2.364936
[3,   280] loss: 2.184474
[3,   290] loss: 2.224226
val loss: 1.9157411759562155
best loss: 2.0917013617719955
Patience: 15
time: 260.2127616405487
[4,    10] loss: 2.157545
[4,    20] loss: 2.058676
[4,    30] loss: 2.129077
[4,    40] loss: 2.202464
[4,    50] loss: 2.199058
[4,    60] loss: 2.062339
[4,    70] loss: 2.159284
[4,    80] loss: 2.253365
[4,    90] loss: 2.115094
[4,   100] loss: 2.055926
[4,   110] loss: 2.322265
[4,   120] loss: 2.237098
[4,   130] loss: 2.249116
[4,   140] loss: 2.099400
[4,   150] loss: 2.181075
[4,   160] loss: 2.175658
[4,   170] loss: 2.152441
[4,   180] loss: 2.094052
[4,   190] loss: 2.192742
[4,   200] loss: 2.065837
[4,   210] loss: 2.095296
[4,   220] loss: 2.168783
[4,   230] loss: 2.042225
[4,   240] loss: 2.087097
[4,   250] loss: 2.126668
[4,   260] loss: 1.945455
[4,   270] loss: 2.119658
[4,   280] loss: 1.995349
[4,   290] loss: 1.971028
val loss: 1.8064515338830651
best loss: 1.9157411759562155
Patience: 15
time: 347.0093936920166
[5,    10] loss: 1.974877
[5,    20] loss: 1.947184
[5,    30] loss: 1.961585
[5,    40] loss: 1.984536
[5,    50] loss: 1.989347
[5,    60] loss: 1.946548
[5,    70] loss: 2.014395
[5,    80] loss: 2.006899
[5,    90] loss: 2.084542
[5,   100] loss: 1.933397
[5,   110] loss: 2.103491
[5,   120] loss: 1.990299
[5,   130] loss: 1.858889
[5,   140] loss: 1.886194
[5,   150] loss: 1.914803
[5,   160] loss: 2.082053
[5,   170] loss: 2.031504
[5,   180] loss: 1.927959
[5,   190] loss: 2.053796
[5,   200] loss: 2.064095
[5,   210] loss: 1.922038
[5,   220] loss: 1.965068
[5,   230] loss: 1.881041
[5,   240] loss: 1.946938
[5,   250] loss: 1.937092
[5,   260] loss: 1.913586
[5,   270] loss: 1.966966
[5,   280] loss: 1.874285
[5,   290] loss: 1.988370
val loss: 1.7688894753224655
best loss: 1.8064515338830651
Patience: 15
time: 433.81844305992126
[6,    10] loss: 1.857785
[6,    20] loss: 1.809970
[6,    30] loss: 1.907631
[6,    40] loss: 1.910759
[6,    50] loss: 1.838310
[6,    60] loss: 1.898043
[6,    70] loss: 1.780178
[6,    80] loss: 1.830364
[6,    90] loss: 1.748134
[6,   100] loss: 1.883929
[6,   110] loss: 1.903880
[6,   120] loss: 1.765112
[6,   130] loss: 1.862539
[6,   140] loss: 1.852781
[6,   150] loss: 1.845161
[6,   160] loss: 1.877769
[6,   170] loss: 1.806306
[6,   180] loss: 1.883115
[6,   190] loss: 1.806313
[6,   200] loss: 1.954595
[6,   210] loss: 1.895145
[6,   220] loss: 1.914487
[6,   230] loss: 1.734341
[6,   240] loss: 1.740269
[6,   250] loss: 1.849535
[6,   260] loss: 1.776847
[6,   270] loss: 1.827998
[6,   280] loss: 1.819596
[6,   290] loss: 2.032790
val loss: 1.6859428382385087
best loss: 1.7688894753224655
Patience: 15
time: 520.2116992473602
[7,    10] loss: 1.756671
[7,    20] loss: 1.738935
[7,    30] loss: 1.744284
[7,    40] loss: 1.892563
[7,    50] loss: 1.668306
[7,    60] loss: 1.764856
[7,    70] loss: 1.813598
[7,    80] loss: 1.760855
[7,    90] loss: 1.820178
[7,   100] loss: 1.841636
[7,   110] loss: 1.845336
[7,   120] loss: 1.807688
[7,   130] loss: 1.738854
[7,   140] loss: 1.894463
[7,   150] loss: 1.699231
[7,   160] loss: 1.701698
[7,   170] loss: 1.706378
[7,   180] loss: 1.773950
[7,   190] loss: 1.816245
[7,   200] loss: 1.623039
[7,   210] loss: 1.819371
[7,   220] loss: 1.745627
[7,   230] loss: 1.809785
[7,   240] loss: 1.681933
[7,   250] loss: 1.724925
[7,   260] loss: 1.733492
[7,   270] loss: 1.740582
[7,   280] loss: 1.741038
[7,   290] loss: 1.705587
val loss: 1.6676638239796095
best loss: 1.6859428382385087
Patience: 15
time: 606.8820495605469
[8,    10] loss: 1.579182
[8,    20] loss: 1.689736
[8,    30] loss: 1.661153
[8,    40] loss: 1.598382
[8,    50] loss: 1.637743
[8,    60] loss: 1.643765
[8,    70] loss: 1.581881
[8,    80] loss: 1.626307
[8,    90] loss: 1.721095
[8,   100] loss: 1.660036
[8,   110] loss: 1.641891
[8,   120] loss: 1.767303
[8,   130] loss: 1.694888
[8,   140] loss: 1.750546
[8,   150] loss: 1.794258
[8,   160] loss: 1.775929
[8,   170] loss: 1.750217
[8,   180] loss: 1.717234
[8,   190] loss: 1.659567
[8,   200] loss: 1.626440
[8,   210] loss: 1.679747
[8,   220] loss: 1.644696
[8,   230] loss: 1.772358
[8,   240] loss: 1.723775
[8,   250] loss: 1.666196
[8,   260] loss: 1.740403
[8,   270] loss: 1.665865
[8,   280] loss: 1.704368
[8,   290] loss: 1.623871
val loss: 1.641250799825318
best loss: 1.6676638239796095
Patience: 15
time: 693.4131863117218
[9,    10] loss: 1.543824
[9,    20] loss: 1.543027
[9,    30] loss: 1.594094
[9,    40] loss: 1.674124
[9,    50] loss: 1.655726
[9,    60] loss: 1.613967
[9,    70] loss: 1.521420
[9,    80] loss: 1.522559
[9,    90] loss: 1.662062
[9,   100] loss: 1.740731
[9,   110] loss: 1.707539
[9,   120] loss: 1.608093
[9,   130] loss: 1.699762
[9,   140] loss: 1.654673
[9,   150] loss: 1.739744
[9,   160] loss: 1.521397
[9,   170] loss: 1.568197
[9,   180] loss: 1.671221
[9,   190] loss: 1.609386
[9,   200] loss: 1.617553
[9,   210] loss: 1.628745
[9,   220] loss: 1.623159
[9,   230] loss: 1.566617
[9,   240] loss: 1.483519
[9,   250] loss: 1.597637
[9,   260] loss: 1.623941
[9,   270] loss: 1.597551
[9,   280] loss: 1.625532
[9,   290] loss: 1.537611
val loss: 1.6245240985222582
best loss: 1.641250799825318
Patience: 15
time: 780.080982208252
[10,    10] loss: 1.570590
[10,    20] loss: 1.721015
[10,    30] loss: 1.622062
[10,    40] loss: 1.603375
[10,    50] loss: 1.595127
[10,    60] loss: 1.518493
[10,    70] loss: 1.551576
[10,    80] loss: 1.484904
[10,    90] loss: 1.616893
[10,   100] loss: 1.576854
[10,   110] loss: 1.535247
[10,   120] loss: 1.438985
[10,   130] loss: 1.593836
[10,   140] loss: 1.480750
[10,   150] loss: 1.482296
[10,   160] loss: 1.525511
[10,   170] loss: 1.530163
[10,   180] loss: 1.623883
[10,   190] loss: 1.536002
[10,   200] loss: 1.627319
[10,   210] loss: 1.513471
[10,   220] loss: 1.499104
[10,   230] loss: 1.538937
[10,   240] loss: 1.456099
[10,   250] loss: 1.574863
[10,   260] loss: 1.627329
[10,   270] loss: 1.475358
[10,   280] loss: 1.460475
[10,   290] loss: 1.603897
val loss: 1.6170100725921694
best loss: 1.6245240985222582
Patience: 15
time: 866.7145843505859
[11,    10] loss: 1.497082
[11,    20] loss: 1.535889
[11,    30] loss: 1.496040
[11,    40] loss: 1.561804
[11,    50] loss: 1.490895
[11,    60] loss: 1.470816
[11,    70] loss: 1.544427
[11,    80] loss: 1.578507
[11,    90] loss: 1.419918
[11,   100] loss: 1.359811
[11,   110] loss: 1.567125
[11,   120] loss: 1.506190
[11,   130] loss: 1.491686
[11,   140] loss: 1.520816
[11,   150] loss: 1.576347
[11,   160] loss: 1.371948
[11,   170] loss: 1.513714
[11,   180] loss: 1.574574
[11,   190] loss: 1.456638
[11,   200] loss: 1.449068
[11,   210] loss: 1.486709
[11,   220] loss: 1.459550
[11,   230] loss: 1.491518
[11,   240] loss: 1.553121
[11,   250] loss: 1.538228
[11,   260] loss: 1.433124
[11,   270] loss: 1.522264
[11,   280] loss: 1.428971
[11,   290] loss: 1.578029
val loss: 1.6202569034787422
best loss: 1.6170100725921694
Patience: 15
time: 953.4056556224823
[12,    10] loss: 1.512431
[12,    20] loss: 1.524342
[12,    30] loss: 1.375395
[12,    40] loss: 1.430120
[12,    50] loss: 1.506628
[12,    60] loss: 1.420391
[12,    70] loss: 1.555911
[12,    80] loss: 1.442257
[12,    90] loss: 1.456141
[12,   100] loss: 1.411668
[12,   110] loss: 1.430551
[12,   120] loss: 1.361743
[12,   130] loss: 1.425042
[12,   140] loss: 1.535921
[12,   150] loss: 1.383466
[12,   160] loss: 1.441654
[12,   170] loss: 1.507432
[12,   180] loss: 1.435066
[12,   190] loss: 1.489545
[12,   200] loss: 1.497527
[12,   210] loss: 1.439011
[12,   220] loss: 1.283233
[12,   230] loss: 1.411272
[12,   240] loss: 1.422002
[12,   250] loss: 1.412561
[12,   260] loss: 1.506292
[12,   270] loss: 1.401229
[12,   280] loss: 1.548665
[12,   290] loss: 1.492538
val loss: 1.5925216281092989
best loss: 1.6170100725921694
Patience: 14
time: 1040.2791426181793
[13,    10] loss: 1.440019
[13,    20] loss: 1.385894
[13,    30] loss: 1.483049
[13,    40] loss: 1.429575
[13,    50] loss: 1.281260
[13,    60] loss: 1.374716
[13,    70] loss: 1.437398
[13,    80] loss: 1.422647
[13,    90] loss: 1.389461
[13,   100] loss: 1.480138
[13,   110] loss: 1.394177
[13,   120] loss: 1.393292
[13,   130] loss: 1.404598
[13,   140] loss: 1.471759
[13,   150] loss: 1.406142
[13,   160] loss: 1.418952
[13,   170] loss: 1.435643
[13,   180] loss: 1.424154
[13,   190] loss: 1.340915
[13,   200] loss: 1.310414
[13,   210] loss: 1.414345
[13,   220] loss: 1.427607
[13,   230] loss: 1.365138
[13,   240] loss: 1.292257
[13,   250] loss: 1.461867
[13,   260] loss: 1.426132
[13,   270] loss: 1.524524
[13,   280] loss: 1.417154
[13,   290] loss: 1.468103
val loss: 1.5813968721810243
best loss: 1.5925216281092989
Patience: 15
time: 1126.898298740387
[14,    10] loss: 1.376268
[14,    20] loss: 1.285833
[14,    30] loss: 1.357232
[14,    40] loss: 1.391664
[14,    50] loss: 1.306190
[14,    60] loss: 1.324455
[14,    70] loss: 1.384479
[14,    80] loss: 1.289208
[14,    90] loss: 1.420330
[14,   100] loss: 1.402464
[14,   110] loss: 1.573099
[14,   120] loss: 1.338308
[14,   130] loss: 1.380715
[14,   140] loss: 1.448959
[14,   150] loss: 1.403452
[14,   160] loss: 1.389061
[14,   170] loss: 1.415141
[14,   180] loss: 1.272797
[14,   190] loss: 1.419305
[14,   200] loss: 1.296276
[14,   210] loss: 1.340189
[14,   220] loss: 1.388480
[14,   230] loss: 1.413986
[14,   240] loss: 1.364332
[14,   250] loss: 1.321853
[14,   260] loss: 1.295206
[14,   270] loss: 1.360925
[14,   280] loss: 1.269187
[14,   290] loss: 1.356936
val loss: 1.5925464061090513
best loss: 1.5813968721810243
Patience: 15
time: 1213.581274986267
[15,    10] loss: 1.367598
[15,    20] loss: 1.302411
[15,    30] loss: 1.377114
[15,    40] loss: 1.377471
[15,    50] loss: 1.262498
[15,    60] loss: 1.385806
[15,    70] loss: 1.360591
[15,    80] loss: 1.361935
[15,    90] loss: 1.344788
[15,   100] loss: 1.336632
[15,   110] loss: 1.361095
[15,   120] loss: 1.390808
[15,   130] loss: 1.394564
[15,   140] loss: 1.317204
[15,   150] loss: 1.332577
[15,   160] loss: 1.335938
[15,   170] loss: 1.344956
[15,   180] loss: 1.255920
[15,   190] loss: 1.214140
[15,   200] loss: 1.320131
[15,   210] loss: 1.293994
[15,   220] loss: 1.349788
[15,   230] loss: 1.327976
[15,   240] loss: 1.252384
[15,   250] loss: 1.286803
[15,   260] loss: 1.411033
[15,   270] loss: 1.272122
[15,   280] loss: 1.304498
[15,   290] loss: 1.327412
val loss: 1.5883375086951228
best loss: 1.5813968721810243
Patience: 14
time: 1300.4388344287872
[16,    10] loss: 1.285842
[16,    20] loss: 1.270825
[16,    30] loss: 1.248980
[16,    40] loss: 1.241300
[16,    50] loss: 1.220764
[16,    60] loss: 1.272303
[16,    70] loss: 1.337155
[16,    80] loss: 1.351751
[16,    90] loss: 1.304437
[16,   100] loss: 1.335920
[16,   110] loss: 1.402832
[16,   120] loss: 1.329415
[16,   130] loss: 1.299070
[16,   140] loss: 1.269806
[16,   150] loss: 1.302958
[16,   160] loss: 1.323947
[16,   170] loss: 1.251115
[16,   180] loss: 1.280467
[16,   190] loss: 1.272414
[16,   200] loss: 1.379437
[16,   210] loss: 1.204208
[16,   220] loss: 1.314608
[16,   230] loss: 1.323517
[16,   240] loss: 1.370838
[16,   250] loss: 1.342148
[16,   260] loss: 1.364921
[16,   270] loss: 1.191564
[16,   280] loss: 1.264722
[16,   290] loss: 1.349728
val loss: 1.5824836702659002
best loss: 1.5813968721810243
Patience: 13
time: 1387.6781678199768
[17,    10] loss: 1.147385
[17,    20] loss: 1.332425
[17,    30] loss: 1.156289
[17,    40] loss: 1.248857
[17,    50] loss: 1.139735
[17,    60] loss: 1.267710
[17,    70] loss: 1.330125
[17,    80] loss: 1.161980
[17,    90] loss: 1.188048
[17,   100] loss: 1.340955
[17,   110] loss: 1.253047
[17,   120] loss: 1.308861
[17,   130] loss: 1.341075
[17,   140] loss: 1.255267
[17,   150] loss: 1.291899
[17,   160] loss: 1.320599
[17,   170] loss: 1.239446
[17,   180] loss: 1.379652
[17,   190] loss: 1.129286
[17,   200] loss: 1.291805
[17,   210] loss: 1.324905
[17,   220] loss: 1.269884
[17,   230] loss: 1.224206
[17,   240] loss: 1.296427
[17,   250] loss: 1.230221
[17,   260] loss: 1.291946
[17,   270] loss: 1.174461
[17,   280] loss: 1.226776
[17,   290] loss: 1.298223
val loss: 1.5798728437197629
best loss: 1.5813968721810243
Patience: 12
time: 1474.8544702529907
[18,    10] loss: 1.203656
[18,    20] loss: 1.149489
[18,    30] loss: 1.232907
[18,    40] loss: 1.237421
[18,    50] loss: 1.157207
[18,    60] loss: 1.202505
[18,    70] loss: 1.167446
[18,    80] loss: 1.238918
[18,    90] loss: 1.159579
[18,   100] loss: 1.160191
[18,   110] loss: 1.141034
[18,   120] loss: 1.319093
[18,   130] loss: 1.264346
[18,   140] loss: 1.263695
[18,   150] loss: 1.346831
[18,   160] loss: 1.278995
[18,   170] loss: 1.316096
[18,   180] loss: 1.193589
[18,   190] loss: 1.078535
[18,   200] loss: 1.165511
[18,   210] loss: 1.244933
[18,   220] loss: 1.253366
[18,   230] loss: 1.272484
[18,   240] loss: 1.212746
[18,   250] loss: 1.304993
[18,   260] loss: 1.296803
[18,   270] loss: 1.303026
[18,   280] loss: 1.229470
[18,   290] loss: 1.193996
val loss: 1.606304281278111
best loss: 1.5798728437197629
Patience: 15
time: 1561.7572073936462
[19,    10] loss: 1.154450
[19,    20] loss: 1.167728
[19,    30] loss: 1.201608
[19,    40] loss: 1.170648
[19,    50] loss: 1.263231
[19,    60] loss: 1.246472
[19,    70] loss: 1.087483
[19,    80] loss: 1.204470
[19,    90] loss: 1.218342
[19,   100] loss: 1.152181
[19,   110] loss: 1.244171
[19,   120] loss: 1.128584
[19,   130] loss: 1.290937
[19,   140] loss: 1.171015
[19,   150] loss: 1.262079
[19,   160] loss: 1.110349
[19,   170] loss: 1.179049
[19,   180] loss: 1.211232
[19,   190] loss: 1.196543
[19,   200] loss: 1.281331
[19,   210] loss: 1.263652
[19,   220] loss: 1.175884
[19,   230] loss: 1.181737
[19,   240] loss: 1.280999
[19,   250] loss: 1.236681
[19,   260] loss: 1.204134
[19,   270] loss: 1.111031
[19,   280] loss: 1.224850
[19,   290] loss: 1.163355
val loss: 1.5915206874729915
best loss: 1.5798728437197629
Patience: 14
time: 1648.4796760082245
[20,    10] loss: 1.200332
[20,    20] loss: 1.198687
[20,    30] loss: 1.195954
[20,    40] loss: 1.168069
[20,    50] loss: 1.118993
[20,    60] loss: 1.137152
[20,    70] loss: 1.116870
[20,    80] loss: 1.080543
[20,    90] loss: 1.191777
[20,   100] loss: 1.111150
[20,   110] loss: 1.260182
[20,   120] loss: 1.211597
[20,   130] loss: 1.147328
[20,   140] loss: 1.197709
[20,   150] loss: 1.183782
[20,   160] loss: 1.126359
[20,   170] loss: 1.204631
[20,   180] loss: 1.219759
[20,   190] loss: 1.106787
[20,   200] loss: 1.144167
[20,   210] loss: 1.164427
[20,   220] loss: 1.199789
[20,   230] loss: 1.148297
[20,   240] loss: 1.124345
[20,   250] loss: 1.229096
[20,   260] loss: 1.212572
[20,   270] loss: 1.120439
[20,   280] loss: 1.195308
[20,   290] loss: 1.163551
val loss: 1.6062202878083707
best loss: 1.5798728437197629
Patience: 13
time: 1735.2976582050323
[21,    10] loss: 1.125035
[21,    20] loss: 1.049501
[21,    30] loss: 1.172733
[21,    40] loss: 1.175238
[21,    50] loss: 1.035291
[21,    60] loss: 1.166375
[21,    70] loss: 1.216764
[21,    80] loss: 1.073867
[21,    90] loss: 1.067305
[21,   100] loss: 1.126434
[21,   110] loss: 1.220773
[21,   120] loss: 1.112297
[21,   130] loss: 1.079741
[21,   140] loss: 1.104514
[21,   150] loss: 1.093933
[21,   160] loss: 1.156535
[21,   170] loss: 1.142183
[21,   180] loss: 1.182700
[21,   190] loss: 1.132234
[21,   200] loss: 1.109286
[21,   210] loss: 1.098872
[21,   220] loss: 1.249866
[21,   230] loss: 1.242299
[21,   240] loss: 1.139573
[21,   250] loss: 1.121653
[21,   260] loss: 1.120515
[21,   270] loss: 1.205996
[21,   280] loss: 1.113538
[21,   290] loss: 1.071056
val loss: 1.6048978877209825
best loss: 1.5798728437197629
Patience: 12
time: 1822.2257096767426
[22,    10] loss: 1.171598
[22,    20] loss: 1.178034
[22,    30] loss: 1.155295
[22,    40] loss: 1.007686
[22,    50] loss: 1.097823
[22,    60] loss: 1.036742
[22,    70] loss: 1.183599
[22,    80] loss: 1.079269
[22,    90] loss: 1.069991
[22,   100] loss: 1.093791
[22,   110] loss: 1.010462
[22,   120] loss: 1.126282
[22,   130] loss: 1.114774
[22,   140] loss: 1.112785
[22,   150] loss: 1.105232
[22,   160] loss: 1.134962
[22,   170] loss: 1.148338
[22,   180] loss: 1.206582
[22,   190] loss: 1.133191
[22,   200] loss: 1.195630
[22,   210] loss: 1.147202
[22,   220] loss: 1.047869
[22,   230] loss: 1.111736
[22,   240] loss: 1.007262
[22,   250] loss: 1.090878
[22,   260] loss: 1.193344
[22,   270] loss: 1.121829
[22,   280] loss: 1.132815
[22,   290] loss: 1.111837
val loss: 1.6202635535154202
best loss: 1.5798728437197629
Patience: 11
time: 1909.1019010543823
[23,    10] loss: 0.992323
[23,    20] loss: 1.036064
[23,    30] loss: 1.107066
[23,    40] loss: 1.179072
[23,    50] loss: 1.017721
[23,    60] loss: 1.091658
[23,    70] loss: 1.075184
[23,    80] loss: 1.112584
[23,    90] loss: 1.160616
[23,   100] loss: 1.090840
[23,   110] loss: 1.055647
[23,   120] loss: 1.162291
[23,   130] loss: 1.152530
[23,   140] loss: 1.117561
[23,   150] loss: 1.146374
[23,   160] loss: 1.009343
[23,   170] loss: 1.013461
[23,   180] loss: 1.115353
[23,   190] loss: 1.002052
[23,   200] loss: 1.051483
[23,   210] loss: 1.052403
[23,   220] loss: 1.074346
[23,   230] loss: 1.151421
[23,   240] loss: 1.069465
[23,   250] loss: 1.081393
[23,   260] loss: 1.067935
[23,   270] loss: 1.150007
[23,   280] loss: 1.098854
[23,   290] loss: 1.090461
val loss: 1.6590977991575042
best loss: 1.5798728437197629
Patience: 10
time: 1996.2984087467194
[24,    10] loss: 1.021363
[24,    20] loss: 1.043926
[24,    30] loss: 1.117132
[24,    40] loss: 1.138955
[24,    50] loss: 1.094309
[24,    60] loss: 1.054524
[24,    70] loss: 1.130411
[24,    80] loss: 1.152051
[24,    90] loss: 1.071254
[24,   100] loss: 1.126373
[24,   110] loss: 1.094431
[24,   120] loss: 1.076293
[24,   130] loss: 1.065498
[24,   140] loss: 1.109944
[24,   150] loss: 1.035766
[24,   160] loss: 1.075472
[24,   170] loss: 1.147342
[24,   180] loss: 0.965264
[24,   190] loss: 0.976602
[24,   200] loss: 1.114341
[24,   210] loss: 1.075484
[24,   220] loss: 1.039798
[24,   230] loss: 1.011103
[24,   240] loss: 0.965529
[24,   250] loss: 1.071503
[24,   260] loss: 1.041545
[24,   270] loss: 1.073420
[24,   280] loss: 1.074024
[24,   290] loss: 1.082463
val loss: 1.6410588998214755
best loss: 1.5798728437197629
Patience: 9
time: 2083.508536338806
[25,    10] loss: 1.001223
[25,    20] loss: 1.023109
[25,    30] loss: 1.029797
[25,    40] loss: 1.009417
[25,    50] loss: 1.050226
[25,    60] loss: 1.031658
[25,    70] loss: 1.000882
[25,    80] loss: 1.074818
[25,    90] loss: 1.020765
[25,   100] loss: 1.064777
[25,   110] loss: 1.059970
[25,   120] loss: 1.042294
[25,   130] loss: 1.065959
[25,   140] loss: 1.030649
[25,   150] loss: 1.045951
[25,   160] loss: 1.035664
[25,   170] loss: 1.078953
[25,   180] loss: 1.100434
[25,   190] loss: 1.085969
[25,   200] loss: 1.032798
[25,   210] loss: 1.012221
[25,   220] loss: 0.993263
[25,   230] loss: 1.099774
[25,   240] loss: 1.083827
[25,   250] loss: 1.112719
[25,   260] loss: 1.091428
[25,   270] loss: 1.010794
[25,   280] loss: 1.070309
[25,   290] loss: 1.013701
val loss: 1.6315246788729891
best loss: 1.5798728437197629
Patience: 8
time: 2170.5857763290405
[26,    10] loss: 0.998216
[26,    20] loss: 0.954693
[26,    30] loss: 1.052362
[26,    40] loss: 1.013541
[26,    50] loss: 1.090878
[26,    60] loss: 1.092757
[26,    70] loss: 1.032110
[26,    80] loss: 1.047854
[26,    90] loss: 1.066893
[26,   100] loss: 1.015694
[26,   110] loss: 1.032078
[26,   120] loss: 1.048744
[26,   130] loss: 1.098388
[26,   140] loss: 1.007899
[26,   150] loss: 1.013697
[26,   160] loss: 1.005376
[26,   170] loss: 1.000094
[26,   180] loss: 1.001334
[26,   190] loss: 1.008982
[26,   200] loss: 0.967061
[26,   210] loss: 0.982088
[26,   220] loss: 1.018578
[26,   230] loss: 0.968752
[26,   240] loss: 1.079147
[26,   250] loss: 1.004826
[26,   260] loss: 1.035979
[26,   270] loss: 1.142033
[26,   280] loss: 1.035264
[26,   290] loss: 0.961456
val loss: 1.6480260798862298
best loss: 1.5798728437197629
Patience: 7
time: 2257.6466052532196
[27,    10] loss: 1.023264
[27,    20] loss: 0.977973
[27,    30] loss: 0.958732
[27,    40] loss: 1.052221
[27,    50] loss: 0.954698
[27,    60] loss: 0.966717
[27,    70] loss: 0.955983
[27,    80] loss: 1.031160
[27,    90] loss: 1.057083
[27,   100] loss: 1.005130
[27,   110] loss: 1.044791
[27,   120] loss: 1.104005
[27,   130] loss: 1.025786
[27,   140] loss: 1.010396
[27,   150] loss: 1.001292
[27,   160] loss: 0.995174
[27,   170] loss: 0.999975
[27,   180] loss: 1.018886
[27,   190] loss: 1.033833
[27,   200] loss: 1.062387
[27,   210] loss: 0.975637
[27,   220] loss: 1.036582
[27,   230] loss: 0.978557
[27,   240] loss: 1.086898
[27,   250] loss: 0.928452
[27,   260] loss: 0.990384
[27,   270] loss: 1.068362
[27,   280] loss: 1.033632
[27,   290] loss: 0.993106
val loss: 1.6807818942599826
best loss: 1.5798728437197629
Patience: 6
time: 2344.728682279587
[28,    10] loss: 1.023032
[28,    20] loss: 0.947417
[28,    30] loss: 0.964812
[28,    40] loss: 0.986495
[28,    50] loss: 0.949316
[28,    60] loss: 0.958276
[28,    70] loss: 0.922505
[28,    80] loss: 0.940005
[28,    90] loss: 1.078654
[28,   100] loss: 1.016124
[28,   110] loss: 1.023285
[28,   120] loss: 0.990684
[28,   130] loss: 1.011021
[28,   140] loss: 0.982864
[28,   150] loss: 1.015261
[28,   160] loss: 1.005664
[28,   170] loss: 0.981357
[28,   180] loss: 0.935129
[28,   190] loss: 0.992436
[28,   200] loss: 0.929312
[28,   210] loss: 0.949008
[28,   220] loss: 1.005552
[28,   230] loss: 0.987558
[28,   240] loss: 0.880116
[28,   250] loss: 1.026278
[28,   260] loss: 1.022236
[28,   270] loss: 1.042731
[28,   280] loss: 1.036925
[28,   290] loss: 0.978955
val loss: 1.689184015671143
best loss: 1.5798728437197629
Patience: 5
time: 2431.7686607837677
[29,    10] loss: 0.920019
[29,    20] loss: 1.010988
[29,    30] loss: 0.976490
[29,    40] loss: 0.933904
[29,    50] loss: 0.955623
[29,    60] loss: 0.969867
[29,    70] loss: 0.971135
[29,    80] loss: 1.002642
[29,    90] loss: 0.992267
[29,   100] loss: 0.970699
[29,   110] loss: 0.927578
[29,   120] loss: 0.983361
[29,   130] loss: 0.997552
[29,   140] loss: 0.965738
[29,   150] loss: 0.984370
[29,   160] loss: 0.935442
[29,   170] loss: 1.031082
[29,   180] loss: 0.937820
[29,   190] loss: 1.034857
[29,   200] loss: 0.911679
[29,   210] loss: 0.979219
[29,   220] loss: 0.968868
[29,   230] loss: 0.958786
[29,   240] loss: 0.976123
[29,   250] loss: 0.989344
[29,   260] loss: 0.971434
[29,   270] loss: 0.936820
[29,   280] loss: 0.877818
[29,   290] loss: 0.979643
val loss: 1.7027210444139869
best loss: 1.5798728437197629
Patience: 4
time: 2518.8989396095276
[30,    10] loss: 0.905779
[30,    20] loss: 0.981563
[30,    30] loss: 0.898585
[30,    40] loss: 0.900833
[30,    50] loss: 0.941003
[30,    60] loss: 0.989077
[30,    70] loss: 0.880749
[30,    80] loss: 0.843758
[30,    90] loss: 0.900878
[30,   100] loss: 0.917321
[30,   110] loss: 0.956046
[30,   120] loss: 0.942732
[30,   130] loss: 0.947324
[30,   140] loss: 0.945920
[30,   150] loss: 1.061613
[30,   160] loss: 0.894200
[30,   170] loss: 0.892739
[30,   180] loss: 0.905198
[30,   190] loss: 0.973653
[30,   200] loss: 1.003367
[30,   210] loss: 0.923869
[30,   220] loss: 0.991340
[30,   230] loss: 0.951991
[30,   240] loss: 1.055879
[30,   250] loss: 0.976975
[30,   260] loss: 0.952760
[30,   270] loss: 0.963743
[30,   280] loss: 0.957086
[30,   290] loss: 1.001502
val loss: 1.716968187572994
best loss: 1.5798728437197629
Patience: 3
time: 2605.852260828018
[31,    10] loss: 0.988134
[31,    20] loss: 0.895557
[31,    30] loss: 0.878671
[31,    40] loss: 0.867579
[31,    50] loss: 0.931760
[31,    60] loss: 0.914941
[31,    70] loss: 0.962604
[31,    80] loss: 0.985761
[31,    90] loss: 0.978097
[31,   100] loss: 0.893046
[31,   110] loss: 0.872512
[31,   120] loss: 0.995260
[31,   130] loss: 0.896804
[31,   140] loss: 1.037711
[31,   150] loss: 0.856898
[31,   160] loss: 0.877571
[31,   170] loss: 0.895508
[31,   180] loss: 0.913970
[31,   190] loss: 0.961226
[31,   200] loss: 0.967691
[31,   210] loss: 0.920215
[31,   220] loss: 0.926984
[31,   230] loss: 0.924627
[31,   240] loss: 0.966923
[31,   250] loss: 1.023655
[31,   260] loss: 1.019464
[31,   270] loss: 0.955021
[31,   280] loss: 1.037190
[31,   290] loss: 0.868411
val loss: 1.707889776502073
best loss: 1.5798728437197629
Patience: 2
time: 2693.048317193985
[32,    10] loss: 0.906381
[32,    20] loss: 0.888942
[32,    30] loss: 0.939186
[32,    40] loss: 0.875680
[32,    50] loss: 0.890011
[32,    60] loss: 0.972298
[32,    70] loss: 0.902658
[32,    80] loss: 0.977271
[32,    90] loss: 0.931172
[32,   100] loss: 0.968746
[32,   110] loss: 0.912769
[32,   120] loss: 0.916145
[32,   130] loss: 0.928340
[32,   140] loss: 0.902426
[32,   150] loss: 0.949614
[32,   160] loss: 0.869665
[32,   170] loss: 0.883036
[32,   180] loss: 1.000224
[32,   190] loss: 0.850049
[32,   200] loss: 0.977857
[32,   210] loss: 0.868283
[32,   220] loss: 0.877347
[32,   230] loss: 0.911259
[32,   240] loss: 0.920510
[32,   250] loss: 0.834418
[32,   260] loss: 0.917083
[32,   270] loss: 0.901506
[32,   280] loss: 0.946155
[32,   290] loss: 0.940917
val loss: 1.7410701129767534
best loss: 1.5798728437197629
Patience: 1
time: 2780.1548664569855
Early stop: True
Replacing with better model
