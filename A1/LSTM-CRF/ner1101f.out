===============================
2325595.pbshpc
khas140.hpc.iitd.ac.in
===============================
['B-art', 'B-eve', 'B-geo', 'B-gpe', 'B-nat', 'B-org', 'B-per', 'B-tim', 'I-art', 'I-eve', 'I-geo', 'I-gpe', 'I-nat', 'I-org', 'I-per', 'I-tim', 'O', 'PAD_LBL', 'START_LBL'] {'B-art': 0, 'B-eve': 1, 'B-geo': 2, 'B-gpe': 3, 'B-nat': 4, 'B-org': 5, 'B-per': 6, 'B-tim': 7, 'I-art': 8, 'I-eve': 9, 'I-geo': 10, 'I-gpe': 11, 'I-nat': 12, 'I-org': 13, 'I-per': 14, 'I-tim': 15, 'O': 16, 'PAD_LBL': 17, 'START_LBL': 18}
initializing self.T
frozen transition matrix
LinearCRF(
  (lstm): NERModel(
    (embed_model): ChrTokEmbModel(
      (chr_emb_model): ChrEmbModel(
        (embedding): Embedding(95, 16, padding_idx=93)
        (lstm): LSTM(16, 25, batch_first=True, bidirectional=True)
      )
      (tok_emb_model): TokEmbModel(
        (embedding): Embedding(400002, 100, padding_idx=400000)
      )
    )
    (seq_tag_model): SeqTagModel(
      (dropout): Dropout(p=0.5)
      (lstm): LSTM(150, 100, batch_first=True, bidirectional=True)
      (linear): Linear(in_features=200, out_features=19, bias=True)
    )
    (cross_entropy_loss): CrossEntropyLoss()
  )
  (dropout): Dropout(p=0.5)
  (proj): Sequential(
    (0): Linear(in_features=200, out_features=100, bias=True)
    (1): ReLU()
    (2): Linear(in_features=100, out_features=19, bias=True)
  )
)
[1,    10] loss: 30.784435
[1,    20] loss: 28.442716
[1,    30] loss: 25.587139
[1,    40] loss: 24.076101
[1,    50] loss: 21.263108
[1,    60] loss: 20.411642
[1,    70] loss: 19.148093
[1,    80] loss: 17.629895
[1,    90] loss: 17.168132
[1,   100] loss: 16.634621
[1,   110] loss: 14.439655
[1,   120] loss: 14.195766
[1,   130] loss: 12.450699
[1,   140] loss: 11.937812
[1,   150] loss: 11.748904
[1,   160] loss: 11.487249
[1,   170] loss: 10.135145
[1,   180] loss: 9.799280
[1,   190] loss: 10.215268
[1,   200] loss: 9.148163
[1,   210] loss: 9.294426
[1,   220] loss: 8.176457
[1,   230] loss: 8.506845
[1,   240] loss: 7.985921
[1,   250] loss: 8.128776
[1,   260] loss: 7.677781
[1,   270] loss: 7.642778
[1,   280] loss: 7.356823
[1,   290] loss: 7.918859
val loss: 6.081618280876762
best loss: inf
Patience: 15
time: 84.34814357757568
[2,    10] loss: 7.162901
[2,    20] loss: 7.421550
[2,    30] loss: 7.032240
[2,    40] loss: 7.058150
[2,    50] loss: 7.374030
[2,    60] loss: 7.022370
[2,    70] loss: 7.134427
[2,    80] loss: 6.854839
[2,    90] loss: 6.277532
[2,   100] loss: 6.635449
[2,   110] loss: 6.537759
[2,   120] loss: 6.423230
[2,   130] loss: 6.507811
[2,   140] loss: 6.664425
[2,   150] loss: 6.059668
[2,   160] loss: 6.248347
[2,   170] loss: 5.686425
[2,   180] loss: 6.148415
[2,   190] loss: 6.433352
[2,   200] loss: 6.253315
[2,   210] loss: 6.211373
[2,   220] loss: 6.197425
[2,   230] loss: 5.412884
[2,   240] loss: 5.876691
[2,   250] loss: 5.704612
[2,   260] loss: 5.544305
[2,   270] loss: 5.931418
[2,   280] loss: 5.793122
[2,   290] loss: 5.316457
val loss: 4.690314878707662
best loss: 6.081618280876762
Patience: 15
time: 169.05723333358765
[3,    10] loss: 5.493466
[3,    20] loss: 5.709225
[3,    30] loss: 5.428062
[3,    40] loss: 5.474963
[3,    50] loss: 5.709939
[3,    60] loss: 5.628755
[3,    70] loss: 5.638294
[3,    80] loss: 5.089335
[3,    90] loss: 5.017096
[3,   100] loss: 5.403649
[3,   110] loss: 5.210825
[3,   120] loss: 5.145292
[3,   130] loss: 5.290215
[3,   140] loss: 5.453170
[3,   150] loss: 5.145314
[3,   160] loss: 5.175647
[3,   170] loss: 5.067142
[3,   180] loss: 4.993598
[3,   190] loss: 5.358956
[3,   200] loss: 4.704882
[3,   210] loss: 5.140491
[3,   220] loss: 5.203316
[3,   230] loss: 5.120594
[3,   240] loss: 5.106930
[3,   250] loss: 5.031943
[3,   260] loss: 5.114626
[3,   270] loss: 4.870422
[3,   280] loss: 4.810678
[3,   290] loss: 5.002553
val loss: 4.194423932064889
best loss: 4.690314878707662
Patience: 15
time: 254.00852870941162
[4,    10] loss: 4.714981
[4,    20] loss: 4.680965
[4,    30] loss: 4.864003
[4,    40] loss: 5.109066
[4,    50] loss: 4.636359
[4,    60] loss: 4.864389
[4,    70] loss: 5.041919
[4,    80] loss: 4.406717
[4,    90] loss: 4.704325
[4,   100] loss: 4.381470
[4,   110] loss: 4.898271
[4,   120] loss: 4.774194
[4,   130] loss: 4.581020
[4,   140] loss: 4.547094
[4,   150] loss: 4.450751
[4,   160] loss: 4.395730
[4,   170] loss: 5.094757
[4,   180] loss: 4.637791
[4,   190] loss: 4.902369
[4,   200] loss: 4.614590
[4,   210] loss: 4.344220
[4,   220] loss: 4.634264
[4,   230] loss: 4.547499
[4,   240] loss: 4.461743
[4,   250] loss: 4.690491
[4,   260] loss: 4.853322
[4,   270] loss: 4.051125
[4,   280] loss: 4.464220
[4,   290] loss: 4.146756
val loss: 3.941803283642192
best loss: 4.194423932064889
Patience: 15
time: 339.0416624546051
[5,    10] loss: 4.028732
[5,    20] loss: 4.601924
[5,    30] loss: 4.415070
[5,    40] loss: 4.522911
[5,    50] loss: 4.225867
[5,    60] loss: 4.422318
[5,    70] loss: 4.074740
[5,    80] loss: 3.974063
[5,    90] loss: 4.433641
[5,   100] loss: 4.304638
[5,   110] loss: 4.465199
[5,   120] loss: 4.211369
[5,   130] loss: 4.276521
[5,   140] loss: 4.679662
[5,   150] loss: 4.026766
[5,   160] loss: 4.069100
[5,   170] loss: 4.079267
[5,   180] loss: 4.351680
[5,   190] loss: 4.267674
[5,   200] loss: 4.238072
[5,   210] loss: 4.309148
[5,   220] loss: 3.911143
[5,   230] loss: 3.986316
[5,   240] loss: 4.315097
[5,   250] loss: 3.977130
[5,   260] loss: 4.135765
[5,   270] loss: 4.254530
[5,   280] loss: 4.634326
[5,   290] loss: 4.396585
val loss: 3.765884451088723
best loss: 3.941803283642192
Patience: 15
time: 423.8700556755066
[6,    10] loss: 4.320487
[6,    20] loss: 3.902922
[6,    30] loss: 4.330588
[6,    40] loss: 3.980691
[6,    50] loss: 3.780338
[6,    60] loss: 4.018161
[6,    70] loss: 4.241639
[6,    80] loss: 4.132500
[6,    90] loss: 4.128909
[6,   100] loss: 4.246731
[6,   110] loss: 4.185325
[6,   120] loss: 4.112610
[6,   130] loss: 4.027231
[6,   140] loss: 3.896675
[6,   150] loss: 3.456092
[6,   160] loss: 3.933327
[6,   170] loss: 3.674654
[6,   180] loss: 4.395366
[6,   190] loss: 3.954530
[6,   200] loss: 4.040276
[6,   210] loss: 4.230326
[6,   220] loss: 3.664294
[6,   230] loss: 3.894494
[6,   240] loss: 3.837585
[6,   250] loss: 3.728091
[6,   260] loss: 3.987026
[6,   270] loss: 3.778241
[6,   280] loss: 3.963524
[6,   290] loss: 3.862315
val loss: 3.640242764996321
best loss: 3.765884451088723
Patience: 15
time: 508.6598677635193
[7,    10] loss: 4.139192
[7,    20] loss: 3.654833
[7,    30] loss: 3.939902
[7,    40] loss: 3.819210
[7,    50] loss: 3.757405
[7,    60] loss: 3.767655
[7,    70] loss: 3.629144
[7,    80] loss: 4.046173
[7,    90] loss: 3.715312
[7,   100] loss: 3.923094
[7,   110] loss: 3.705845
[7,   120] loss: 3.697990
[7,   130] loss: 3.602036
[7,   140] loss: 3.698614
[7,   150] loss: 3.866330
[7,   160] loss: 3.889867
[7,   170] loss: 3.589606
[7,   180] loss: 3.813943
[7,   190] loss: 3.462109
[7,   200] loss: 3.760484
[7,   210] loss: 3.686040
[7,   220] loss: 3.687030
[7,   230] loss: 3.498242
[7,   240] loss: 3.667947
[7,   250] loss: 3.576949
[7,   260] loss: 3.891414
[7,   270] loss: 3.760395
[7,   280] loss: 3.965192
[7,   290] loss: 3.798084
val loss: 3.565175991984187
best loss: 3.640242764996321
Patience: 15
time: 593.4843401908875
[8,    10] loss: 3.557519
[8,    20] loss: 3.845642
[8,    30] loss: 3.314429
[8,    40] loss: 3.609893
[8,    50] loss: 3.592498
[8,    60] loss: 3.788274
[8,    70] loss: 3.402081
[8,    80] loss: 3.824258
[8,    90] loss: 3.656131
[8,   100] loss: 3.526445
[8,   110] loss: 3.760586
[8,   120] loss: 3.622601
[8,   130] loss: 3.491216
[8,   140] loss: 3.700187
[8,   150] loss: 3.346418
[8,   160] loss: 3.568559
[8,   170] loss: 3.492581
[8,   180] loss: 3.434686
[8,   190] loss: 3.670326
[8,   200] loss: 3.706315
[8,   210] loss: 3.462034
[8,   220] loss: 3.786013
[8,   230] loss: 3.485291
[8,   240] loss: 3.401409
[8,   250] loss: 3.705289
[8,   260] loss: 3.758086
[8,   270] loss: 3.761819
[8,   280] loss: 3.653564
[8,   290] loss: 3.776247
val loss: 3.5161894989136706
best loss: 3.565175991984187
Patience: 15
time: 678.2166750431061
[9,    10] loss: 3.365144
[9,    20] loss: 3.315570
[9,    30] loss: 3.341184
[9,    40] loss: 3.524970
[9,    50] loss: 3.653601
[9,    60] loss: 3.562533
[9,    70] loss: 3.497896
[9,    80] loss: 3.346403
[9,    90] loss: 3.249896
[9,   100] loss: 3.451441
[9,   110] loss: 3.455698
[9,   120] loss: 3.430191
[9,   130] loss: 3.462282
[9,   140] loss: 3.438976
[9,   150] loss: 3.508432
[9,   160] loss: 3.661364
[9,   170] loss: 3.752884
[9,   180] loss: 3.314949
[9,   190] loss: 3.361857
[9,   200] loss: 3.689654
[9,   210] loss: 3.412589
[9,   220] loss: 3.326557
[9,   230] loss: 3.365659
[9,   240] loss: 3.372932
[9,   250] loss: 3.291679
[9,   260] loss: 3.213240
[9,   270] loss: 3.465758
[9,   280] loss: 3.182135
[9,   290] loss: 3.484436
val loss: 3.4170763064653444
best loss: 3.5161894989136706
Patience: 15
time: 763.0916771888733
[10,    10] loss: 3.478113
[10,    20] loss: 3.178615
[10,    30] loss: 3.106268
[10,    40] loss: 3.389163
[10,    50] loss: 3.134476
[10,    60] loss: 3.274576
[10,    70] loss: 3.214221
[10,    80] loss: 3.418982
[10,    90] loss: 3.135435
[10,   100] loss: 3.292445
[10,   110] loss: 3.385373
[10,   120] loss: 3.294421
[10,   130] loss: 3.446262
[10,   140] loss: 3.263709
[10,   150] loss: 3.428511
[10,   160] loss: 3.414421
[10,   170] loss: 3.196884
[10,   180] loss: 3.172586
[10,   190] loss: 3.297920
[10,   200] loss: 3.449510
[10,   210] loss: 3.296772
[10,   220] loss: 3.553820
[10,   230] loss: 3.256600
[10,   240] loss: 3.247752
[10,   250] loss: 3.223004
[10,   260] loss: 3.238089
[10,   270] loss: 3.133988
[10,   280] loss: 3.350326
[10,   290] loss: 3.401636
val loss: 3.390545096210541
best loss: 3.4170763064653444
Patience: 15
time: 847.9259941577911
[11,    10] loss: 3.062685
[11,    20] loss: 3.201865
[11,    30] loss: 3.128350
[11,    40] loss: 3.101075
[11,    50] loss: 3.369514
[11,    60] loss: 3.307692
[11,    70] loss: 3.200536
[11,    80] loss: 3.088989
[11,    90] loss: 3.041665
[11,   100] loss: 3.263864
[11,   110] loss: 3.362732
[11,   120] loss: 2.914316
[11,   130] loss: 3.381368
[11,   140] loss: 3.158634
[11,   150] loss: 3.088623
[11,   160] loss: 2.999073
[11,   170] loss: 3.378051
[11,   180] loss: 2.909915
[11,   190] loss: 3.061187
[11,   200] loss: 3.192158
[11,   210] loss: 3.002097
[11,   220] loss: 3.200240
[11,   230] loss: 3.324436
[11,   240] loss: 3.231458
[11,   250] loss: 3.160709
[11,   260] loss: 3.482653
[11,   270] loss: 3.344403
[11,   280] loss: 3.095696
[11,   290] loss: 3.010267
val loss: 3.3563743558089167
best loss: 3.390545096210541
Patience: 15
time: 932.9493412971497
[12,    10] loss: 2.809176
[12,    20] loss: 2.909058
[12,    30] loss: 2.993693
[12,    40] loss: 2.850169
[12,    50] loss: 2.874599
[12,    60] loss: 3.171353
[12,    70] loss: 3.159239
[12,    80] loss: 3.087268
[12,    90] loss: 3.021765
[12,   100] loss: 2.989534
[12,   110] loss: 2.976162
[12,   120] loss: 3.154352
[12,   130] loss: 2.989900
[12,   140] loss: 3.124377
[12,   150] loss: 3.131918
[12,   160] loss: 2.973680
[12,   170] loss: 3.175171
[12,   180] loss: 3.066471
[12,   190] loss: 3.259966
[12,   200] loss: 3.016763
[12,   210] loss: 2.945532
[12,   220] loss: 3.092598
[12,   230] loss: 3.075479
[12,   240] loss: 3.031824
[12,   250] loss: 3.319814
[12,   260] loss: 3.413012
[12,   270] loss: 3.184085
[12,   280] loss: 2.973918
[12,   290] loss: 3.152428
val loss: 3.3215327503565453
best loss: 3.3563743558089167
Patience: 15
time: 1017.9817569255829
[13,    10] loss: 2.935017
[13,    20] loss: 3.219488
[13,    30] loss: 2.801604
[13,    40] loss: 3.193603
[13,    50] loss: 2.881877
[13,    60] loss: 3.105009
[13,    70] loss: 3.104070
[13,    80] loss: 2.752450
[13,    90] loss: 2.834251
[13,   100] loss: 2.779875
[13,   110] loss: 2.974011
[13,   120] loss: 2.951712
[13,   130] loss: 2.954224
[13,   140] loss: 2.797699
[13,   150] loss: 2.921315
[13,   160] loss: 2.891436
[13,   170] loss: 3.214290
[13,   180] loss: 2.917574
[13,   190] loss: 3.002828
[13,   200] loss: 2.895961
[13,   210] loss: 3.274374
[13,   220] loss: 2.946339
[13,   230] loss: 2.684086
[13,   240] loss: 2.789105
[13,   250] loss: 3.197074
[13,   260] loss: 3.071986
[13,   270] loss: 2.962493
[13,   280] loss: 3.131033
[13,   290] loss: 2.988609
val loss: 3.327383023234187
best loss: 3.3215327503565453
Patience: 15
time: 1102.6925115585327
===============================
2325612.pbshpc
khas151.hpc.iitd.ac.in
===============================
['B-art', 'B-eve', 'B-geo', 'B-gpe', 'B-nat', 'B-org', 'B-per', 'B-tim', 'I-art', 'I-eve', 'I-geo', 'I-gpe', 'I-nat', 'I-org', 'I-per', 'I-tim', 'O', 'PAD_LBL', 'START_LBL'] {'B-art': 0, 'B-eve': 1, 'B-geo': 2, 'B-gpe': 3, 'B-nat': 4, 'B-org': 5, 'B-per': 6, 'B-tim': 7, 'I-art': 8, 'I-eve': 9, 'I-geo': 10, 'I-gpe': 11, 'I-nat': 12, 'I-org': 13, 'I-per': 14, 'I-tim': 15, 'O': 16, 'PAD_LBL': 17, 'START_LBL': 18}
initializing self.T
===============================
2325617.pbshpc
khas092.hpc.iitd.ac.in
===============================
['B-art', 'B-eve', 'B-geo', 'B-gpe', 'B-nat', 'B-org', 'B-per', 'B-tim', 'I-art', 'I-eve', 'I-geo', 'I-gpe', 'I-nat', 'I-org', 'I-per', 'I-tim', 'O', 'PAD_LBL', 'START_LBL'] {'B-art': 0, 'B-eve': 1, 'B-geo': 2, 'B-gpe': 3, 'B-nat': 4, 'B-org': 5, 'B-per': 6, 'B-tim': 7, 'I-art': 8, 'I-eve': 9, 'I-geo': 10, 'I-gpe': 11, 'I-nat': 12, 'I-org': 13, 'I-per': 14, 'I-tim': 15, 'O': 16, 'PAD_LBL': 17, 'START_LBL': 18}
initializing self.T
===============================
2325632.pbshpc
khas092.hpc.iitd.ac.in
===============================
['B-art', 'B-eve', 'B-geo', 'B-gpe', 'B-nat', 'B-org', 'B-per', 'B-tim', 'I-art', 'I-eve', 'I-geo', 'I-gpe', 'I-nat', 'I-org', 'I-per', 'I-tim', 'O', 'PAD_LBL', 'START_LBL'] {'B-art': 0, 'B-eve': 1, 'B-geo': 2, 'B-gpe': 3, 'B-nat': 4, 'B-org': 5, 'B-per': 6, 'B-tim': 7, 'I-art': 8, 'I-eve': 9, 'I-geo': 10, 'I-gpe': 11, 'I-nat': 12, 'I-org': 13, 'I-per': 14, 'I-tim': 15, 'O': 16, 'PAD_LBL': 17, 'START_LBL': 18}
initializing self.T
frozen transition matrix
LinearCRF(
  (lstm): NERModel(
    (embed_model): ChrTokEmbModel(
      (chr_emb_model): ChrEmbModel(
        (embedding): Embedding(95, 16, padding_idx=93)
        (lstm): LSTM(16, 25, batch_first=True, bidirectional=True)
      )
      (tok_emb_model): TokEmbModel(
        (embedding): Embedding(400002, 100, padding_idx=400000)
      )
    )
    (seq_tag_model): SeqTagModel(
      (dropout): Dropout(p=0.5)
      (lstm): LSTM(150, 100, batch_first=True, bidirectional=True)
      (linear): Linear(in_features=200, out_features=19, bias=True)
    )
    (cross_entropy_loss): CrossEntropyLoss()
  )
  (dropout): Dropout(p=0.5)
  (proj): Sequential(
    (0): Linear(in_features=200, out_features=100, bias=True)
    (1): ReLU()
    (2): Linear(in_features=100, out_features=19, bias=True)
  )
)
[1,    10] loss: 13.052654
[1,    20] loss: 11.492240
[1,    30] loss: 9.738836
[1,    40] loss: 8.292872
[1,    50] loss: 7.172275
[1,    60] loss: 6.365293
[1,    70] loss: 5.789153
[1,    80] loss: 5.055737
[1,    90] loss: 5.088260
[1,   100] loss: 4.734013
[1,   110] loss: 4.753937
[1,   120] loss: 4.520884
[1,   130] loss: 4.278039
[1,   140] loss: 4.231718
[1,   150] loss: 4.069803
[1,   160] loss: 3.981189
[1,   170] loss: 3.892260
[1,   180] loss: 3.913555
[1,   190] loss: 3.632493
[1,   200] loss: 3.822441
[1,   210] loss: 3.609647
[1,   220] loss: 3.598245
[1,   230] loss: 3.553716
[1,   240] loss: 3.506263
[1,   250] loss: 3.400929
[1,   260] loss: 3.336350
[1,   270] loss: 3.294847
[1,   280] loss: 3.507505
[1,   290] loss: 3.574807
val loss: 2.5816221589370034
best loss: inf
Patience: 15
time: 85.06463265419006
[2,    10] loss: 3.220143
[2,    20] loss: 3.170875
[2,    30] loss: 2.758191
[2,    40] loss: 3.040909
[2,    50] loss: 3.158907
[2,    60] loss: 3.078785
[2,    70] loss: 2.895078
[2,    80] loss: 3.095261
[2,    90] loss: 2.945005
[2,   100] loss: 2.838384
[2,   110] loss: 2.902670
[2,   120] loss: 2.772138
[2,   130] loss: 2.851599
[2,   140] loss: 2.864202
[2,   150] loss: 3.001152
[2,   160] loss: 2.798404
[2,   170] loss: 2.800682
[2,   180] loss: 2.776573
[2,   190] loss: 2.751327
[2,   200] loss: 2.719542
[2,   210] loss: 2.763005
[2,   220] loss: 2.670881
[2,   230] loss: 2.602463
[2,   240] loss: 2.616501
[2,   250] loss: 2.655190
[2,   260] loss: 2.690384
[2,   270] loss: 2.546498
[2,   280] loss: 2.691918
[2,   290] loss: 2.480597
val loss: 2.0844494088044803
best loss: 2.5816221589370034
Patience: 15
time: 170.51163244247437
[3,    10] loss: 2.610274
[3,    20] loss: 2.514597
[3,    30] loss: 2.526796
[3,    40] loss: 2.457462
[3,    50] loss: 2.466873
[3,    60] loss: 2.499007
[3,    70] loss: 2.419352
[3,    80] loss: 2.428046
[3,    90] loss: 2.365178
[3,   100] loss: 2.285374
[3,   110] loss: 2.455451
[3,   120] loss: 2.225646
[3,   130] loss: 2.361926
[3,   140] loss: 2.299052
[3,   150] loss: 2.441331
[3,   160] loss: 2.375100
[3,   170] loss: 2.478829
[3,   180] loss: 2.284585
[3,   190] loss: 2.488754
[3,   200] loss: 2.295361
[3,   210] loss: 2.339706
[3,   220] loss: 2.256450
[3,   230] loss: 2.305970
[3,   240] loss: 2.398975
[3,   250] loss: 2.254744
[3,   260] loss: 2.309482
[3,   270] loss: 2.377308
[3,   280] loss: 2.227614
[3,   290] loss: 2.214836
val loss: 1.9322960910018923
best loss: 2.0844494088044803
Patience: 15
time: 255.85319232940674
[4,    10] loss: 2.268292
[4,    20] loss: 2.217591
[4,    30] loss: 2.229179
[4,    40] loss: 2.223069
[4,    50] loss: 2.147105
[4,    60] loss: 2.181206
[4,    70] loss: 2.114971
[4,    80] loss: 2.226682
[4,    90] loss: 2.202758
[4,   100] loss: 2.139671
[4,   110] loss: 2.119397
[4,   120] loss: 2.181663
[4,   130] loss: 2.120149
[4,   140] loss: 2.099155
[4,   150] loss: 2.006621
[4,   160] loss: 2.175734
[4,   170] loss: 2.167029
[4,   180] loss: 2.114486
[4,   190] loss: 2.148523
[4,   200] loss: 2.180314
[4,   210] loss: 2.148011
[4,   220] loss: 2.153965
[4,   230] loss: 2.061971
[4,   240] loss: 2.191425
[4,   250] loss: 2.102328
[4,   260] loss: 1.968960
[4,   270] loss: 2.113220
[4,   280] loss: 2.191159
[4,   290] loss: 2.010196
val loss: 1.825750277438792
best loss: 1.9322960910018923
Patience: 15
time: 341.1544306278229
[5,    10] loss: 2.098201
[5,    20] loss: 1.977875
[5,    30] loss: 1.951007
[5,    40] loss: 2.020242
[5,    50] loss: 1.975142
[5,    60] loss: 2.034077
[5,    70] loss: 2.018369
[5,    80] loss: 1.936466
[5,    90] loss: 1.940126
[5,   100] loss: 2.100003
[5,   110] loss: 1.985617
[5,   120] loss: 2.064942
[5,   130] loss: 2.061390
[5,   140] loss: 2.080884
[5,   150] loss: 1.962031
[5,   160] loss: 1.799316
[5,   170] loss: 1.947451
[5,   180] loss: 2.038452
[5,   190] loss: 1.942286
[5,   200] loss: 2.001673
[5,   210] loss: 1.899008
[5,   220] loss: 2.093324
[5,   230] loss: 1.902953
[5,   240] loss: 1.968306
[5,   250] loss: 2.032710
[5,   260] loss: 2.017069
[5,   270] loss: 1.921185
[5,   280] loss: 2.045581
[5,   290] loss: 1.898724
val loss: 1.752134954596773
best loss: 1.825750277438792
Patience: 15
time: 426.11117935180664
[6,    10] loss: 1.940393
[6,    20] loss: 1.968326
[6,    30] loss: 1.785078
[6,    40] loss: 1.973663
[6,    50] loss: 1.849406
[6,    60] loss: 1.885133
[6,    70] loss: 2.019072
[6,    80] loss: 1.883805
[6,    90] loss: 1.890964
[6,   100] loss: 1.816466
[6,   110] loss: 1.957442
[6,   120] loss: 1.882531
[6,   130] loss: 1.961731
[6,   140] loss: 1.873015
[6,   150] loss: 1.741001
[6,   160] loss: 1.895596
[6,   170] loss: 1.729123
[6,   180] loss: 1.900245
[6,   190] loss: 1.891728
[6,   200] loss: 1.844172
[6,   210] loss: 1.982955
[6,   220] loss: 1.856363
[6,   230] loss: 1.876573
[6,   240] loss: 1.909854
[6,   250] loss: 1.722229
[6,   260] loss: 1.834810
[6,   270] loss: 1.953762
[6,   280] loss: 1.740948
[6,   290] loss: 1.767480
val loss: 1.7177020981703588
best loss: 1.752134954596773
Patience: 15
time: 511.3524401187897
[7,    10] loss: 1.871673
[7,    20] loss: 1.742572
[7,    30] loss: 1.781234
[7,    40] loss: 1.734839
[7,    50] loss: 1.732919
[7,    60] loss: 1.907867
[7,    70] loss: 1.643319
[7,    80] loss: 1.918319
[7,    90] loss: 1.796857
[7,   100] loss: 1.861916
[7,   110] loss: 1.660431
[7,   120] loss: 1.855629
[7,   130] loss: 1.688372
[7,   140] loss: 1.781516
[7,   150] loss: 1.820662
[7,   160] loss: 1.785361
[7,   170] loss: 1.660970
[7,   180] loss: 1.705741
[7,   190] loss: 1.727613
[7,   200] loss: 1.642539
[7,   210] loss: 1.806383
[7,   220] loss: 1.863599
[7,   230] loss: 1.745859
[7,   240] loss: 1.619880
[7,   250] loss: 1.851754
[7,   260] loss: 1.740109
[7,   270] loss: 1.748688
[7,   280] loss: 1.771475
[7,   290] loss: 1.769785
val loss: 1.6867901574909794
best loss: 1.7177020981703588
Patience: 15
time: 596.4492716789246
[8,    10] loss: 1.646135
[8,    20] loss: 1.716640
[8,    30] loss: 1.660329
[8,    40] loss: 1.768873
[8,    50] loss: 1.690385
[8,    60] loss: 1.710075
[8,    70] loss: 1.656346
[8,    80] loss: 1.651866
[8,    90] loss: 1.713232
[8,   100] loss: 1.700714
[8,   110] loss: 1.563029
[8,   120] loss: 1.709723
[8,   130] loss: 1.786119
[8,   140] loss: 1.654027
[8,   150] loss: 1.763154
[8,   160] loss: 1.694467
[8,   170] loss: 1.831222
[8,   180] loss: 1.853386
[8,   190] loss: 1.608236
[8,   200] loss: 1.663966
[8,   210] loss: 1.759143
[8,   220] loss: 1.668940
[8,   230] loss: 1.636141
[8,   240] loss: 1.638772
[8,   250] loss: 1.600591
[8,   260] loss: 1.685032
[8,   270] loss: 1.681637
[8,   280] loss: 1.715315
[8,   290] loss: 1.717842
val loss: 1.672417651605383
best loss: 1.6867901574909794
Patience: 15
time: 681.499338388443
[9,    10] loss: 1.642249
[9,    20] loss: 1.683774
[9,    30] loss: 1.749206
[9,    40] loss: 1.648394
[9,    50] loss: 1.504234
[9,    60] loss: 1.588630
[9,    70] loss: 1.582591
[9,    80] loss: 1.507453
[9,    90] loss: 1.723794
[9,   100] loss: 1.671065
[9,   110] loss: 1.658458
[9,   120] loss: 1.617111
[9,   130] loss: 1.540519
[9,   140] loss: 1.685262
[9,   150] loss: 1.861691
[9,   160] loss: 1.696376
[9,   170] loss: 1.582334
[9,   180] loss: 1.601426
[9,   190] loss: 1.574706
[9,   200] loss: 1.628239
[9,   210] loss: 1.604479
[9,   220] loss: 1.637995
[9,   230] loss: 1.546883
[9,   240] loss: 1.672459
[9,   250] loss: 1.599927
[9,   260] loss: 1.496663
[9,   270] loss: 1.556512
[9,   280] loss: 1.588289
[9,   290] loss: 1.637330
val loss: 1.6452778516479354
best loss: 1.672417651605383
Patience: 15
time: 766.6668400764465
[10,    10] loss: 1.653834
[10,    20] loss: 1.519278
[10,    30] loss: 1.467566
[10,    40] loss: 1.554955
[10,    50] loss: 1.615610
[10,    60] loss: 1.572004
[10,    70] loss: 1.541028
[10,    80] loss: 1.534827
[10,    90] loss: 1.602782
[10,   100] loss: 1.551280
[10,   110] loss: 1.633015
[10,   120] loss: 1.532688
[10,   130] loss: 1.598627
[10,   140] loss: 1.579430
[10,   150] loss: 1.584208
[10,   160] loss: 1.526955
[10,   170] loss: 1.593855
[10,   180] loss: 1.645876
[10,   190] loss: 1.535403
[10,   200] loss: 1.530223
[10,   210] loss: 1.487606
[10,   220] loss: 1.594466
[10,   230] loss: 1.514452
[10,   240] loss: 1.513458
[10,   250] loss: 1.612243
[10,   260] loss: 1.685404
[10,   270] loss: 1.464911
[10,   280] loss: 1.484548
[10,   290] loss: 1.656097
val loss: 1.6087618875342056
best loss: 1.6452778516479354
Patience: 15
time: 851.8472857475281
[11,    10] loss: 1.463144
[11,    20] loss: 1.509278
[11,    30] loss: 1.550759
[11,    40] loss: 1.555797
[11,    50] loss: 1.518346
[11,    60] loss: 1.472495
[11,    70] loss: 1.452730
[11,    80] loss: 1.483206
[11,    90] loss: 1.497073
[11,   100] loss: 1.364935
[11,   110] loss: 1.548111
[11,   120] loss: 1.452572
[11,   130] loss: 1.488943
[11,   140] loss: 1.547308
[11,   150] loss: 1.552621
[11,   160] loss: 1.546935
[11,   170] loss: 1.457405
[11,   180] loss: 1.500190
[11,   190] loss: 1.535249
[11,   200] loss: 1.569953
[11,   210] loss: 1.587091
[11,   220] loss: 1.562853
[11,   230] loss: 1.487473
[11,   240] loss: 1.520996
[11,   250] loss: 1.516017
[11,   260] loss: 1.397791
[11,   270] loss: 1.595905
[11,   280] loss: 1.538470
[11,   290] loss: 1.485061
val loss: 1.6358704009453648
best loss: 1.6087618875342056
Patience: 15
time: 937.107729434967
[12,    10] loss: 1.511920
[12,    20] loss: 1.545469
[12,    30] loss: 1.500304
[12,    40] loss: 1.329978
[12,    50] loss: 1.486264
[12,    60] loss: 1.417654
[12,    70] loss: 1.371390
[12,    80] loss: 1.562060
[12,    90] loss: 1.451050
[12,   100] loss: 1.501145
[12,   110] loss: 1.468601
[12,   120] loss: 1.434342
[12,   130] loss: 1.412683
[12,   140] loss: 1.487304
[12,   150] loss: 1.467264
[12,   160] loss: 1.477891
[12,   170] loss: 1.402321
[12,   180] loss: 1.602785
[12,   190] loss: 1.402981
[12,   200] loss: 1.505875
[12,   210] loss: 1.449873
[12,   220] loss: 1.359665
[12,   230] loss: 1.357548
[12,   240] loss: 1.571689
[12,   250] loss: 1.421665
[12,   260] loss: 1.496568
[12,   270] loss: 1.462858
[12,   280] loss: 1.493957
[12,   290] loss: 1.470269
val loss: 1.6266624070505733
best loss: 1.6087618875342056
Patience: 14
time: 1022.4325454235077
[13,    10] loss: 1.455241
[13,    20] loss: 1.424100
[13,    30] loss: 1.443217
[13,    40] loss: 1.418696
[13,    50] loss: 1.397983
[13,    60] loss: 1.402542
[13,    70] loss: 1.486551
[13,    80] loss: 1.362480
[13,    90] loss: 1.415866
[13,   100] loss: 1.396901
[13,   110] loss: 1.312563
[13,   120] loss: 1.324561
[13,   130] loss: 1.368701
[13,   140] loss: 1.419114
[13,   150] loss: 1.408909
[13,   160] loss: 1.491880
[13,   170] loss: 1.479078
[13,   180] loss: 1.416673
[13,   190] loss: 1.449356
[13,   200] loss: 1.347465
[13,   210] loss: 1.355128
[13,   220] loss: 1.366090
[13,   230] loss: 1.348827
[13,   240] loss: 1.522259
[13,   250] loss: 1.392518
[13,   260] loss: 1.401903
[13,   270] loss: 1.411322
[13,   280] loss: 1.389174
[13,   290] loss: 1.529216
val loss: 1.6171545721680631
best loss: 1.6087618875342056
Patience: 13
time: 1107.864567041397
[14,    10] loss: 1.384281
[14,    20] loss: 1.333801
[14,    30] loss: 1.329269
[14,    40] loss: 1.369017
[14,    50] loss: 1.423364
[14,    60] loss: 1.339163
[14,    70] loss: 1.424297
[14,    80] loss: 1.380169
[14,    90] loss: 1.309879
[14,   100] loss: 1.383239
[14,   110] loss: 1.366536
[14,   120] loss: 1.283728
[14,   130] loss: 1.406051
[14,   140] loss: 1.309267
[14,   150] loss: 1.259749
[14,   160] loss: 1.404118
[14,   170] loss: 1.361289
[14,   180] loss: 1.365408
[14,   190] loss: 1.434829
[14,   200] loss: 1.361984
[14,   210] loss: 1.444160
[14,   220] loss: 1.407258
[14,   230] loss: 1.405487
[14,   240] loss: 1.464122
[14,   250] loss: 1.442398
[14,   260] loss: 1.381667
[14,   270] loss: 1.345721
[14,   280] loss: 1.500098
[14,   290] loss: 1.370249
val loss: 1.6019244047157843
best loss: 1.6087618875342056
Patience: 12
time: 1193.2128586769104
[15,    10] loss: 1.294306
[15,    20] loss: 1.370258
[15,    30] loss: 1.412857
[15,    40] loss: 1.317515
[15,    50] loss: 1.294190
[15,    60] loss: 1.324614
[15,    70] loss: 1.391895
[15,    80] loss: 1.288209
[15,    90] loss: 1.440766
[15,   100] loss: 1.315577
[15,   110] loss: 1.323766
[15,   120] loss: 1.335726
[15,   130] loss: 1.315055
[15,   140] loss: 1.345973
[15,   150] loss: 1.329704
[15,   160] loss: 1.388669
[15,   170] loss: 1.291877
[15,   180] loss: 1.449228
[15,   190] loss: 1.284498
[15,   200] loss: 1.248450
[15,   210] loss: 1.359348
[15,   220] loss: 1.314347
[15,   230] loss: 1.266100
[15,   240] loss: 1.269679
[15,   250] loss: 1.388417
[15,   260] loss: 1.331988
[15,   270] loss: 1.297262
[15,   280] loss: 1.376244
[15,   290] loss: 1.341609
val loss: 1.6001292959064692
best loss: 1.6019244047157843
Patience: 15
time: 1278.5291242599487
[16,    10] loss: 1.344517
[16,    20] loss: 1.396241
[16,    30] loss: 1.400521
[16,    40] loss: 1.283787
[16,    50] loss: 1.353845
[16,    60] loss: 1.314902
[16,    70] loss: 1.258353
[16,    80] loss: 1.428330
[16,    90] loss: 1.286072
[16,   100] loss: 1.352454
[16,   110] loss: 1.245252
[16,   120] loss: 1.320797
[16,   130] loss: 1.278234
[16,   140] loss: 1.284814
[16,   150] loss: 1.304699
[16,   160] loss: 1.331853
[16,   170] loss: 1.248335
[16,   180] loss: 1.208377
[16,   190] loss: 1.204428
[16,   200] loss: 1.240521
[16,   210] loss: 1.316445
[16,   220] loss: 1.361108
[16,   230] loss: 1.334588
[16,   240] loss: 1.296841
[16,   250] loss: 1.233867
[16,   260] loss: 1.292011
[16,   270] loss: 1.381107
[16,   280] loss: 1.267734
[16,   290] loss: 1.324932
val loss: 1.593341617618063
best loss: 1.6001292959064692
Patience: 15
time: 1363.895169019699
[17,    10] loss: 1.203466
[17,    20] loss: 1.341272
[17,    30] loss: 1.275064
[17,    40] loss: 1.152838
[17,    50] loss: 1.270523
[17,    60] loss: 1.236754
[17,    70] loss: 1.240976
[17,    80] loss: 1.233861
[17,    90] loss: 1.213942
[17,   100] loss: 1.207920
[17,   110] loss: 1.272144
[17,   120] loss: 1.385559
[17,   130] loss: 1.263046
[17,   140] loss: 1.343768
[17,   150] loss: 1.192562
[17,   160] loss: 1.261452
[17,   170] loss: 1.304720
[17,   180] loss: 1.226652
[17,   190] loss: 1.308931
[17,   200] loss: 1.242575
[17,   210] loss: 1.182277
[17,   220] loss: 1.297706
[17,   230] loss: 1.297893
[17,   240] loss: 1.244844
[17,   250] loss: 1.279151
[17,   260] loss: 1.373137
[17,   270] loss: 1.302833
[17,   280] loss: 1.334019
[17,   290] loss: 1.347226
val loss: 1.589790438975159
best loss: 1.593341617618063
Patience: 15
time: 1448.9910814762115
[18,    10] loss: 1.158826
[18,    20] loss: 1.255117
[18,    30] loss: 1.267099
[18,    40] loss: 1.209916
[18,    50] loss: 1.213803
[18,    60] loss: 1.245972
[18,    70] loss: 1.204558
[18,    80] loss: 1.245860
[18,    90] loss: 1.279534
[18,   100] loss: 1.087537
[18,   110] loss: 1.183423
[18,   120] loss: 1.214122
[18,   130] loss: 1.287978
[18,   140] loss: 1.270885
[18,   150] loss: 1.241008
[18,   160] loss: 1.287391
[18,   170] loss: 1.177812
[18,   180] loss: 1.272707
[18,   190] loss: 1.314469
[18,   200] loss: 1.245253
[18,   210] loss: 1.242362
[18,   220] loss: 1.237130
[18,   230] loss: 1.192870
[18,   240] loss: 1.184424
[18,   250] loss: 1.200096
[18,   260] loss: 1.234815
[18,   270] loss: 1.310470
[18,   280] loss: 1.294681
[18,   290] loss: 1.207106
val loss: 1.5934858711241446
best loss: 1.589790438975159
Patience: 15
time: 1534.2392473220825
[19,    10] loss: 1.239201
[19,    20] loss: 1.232665
[19,    30] loss: 1.099167
[19,    40] loss: 1.131824
[19,    50] loss: 1.196109
[19,    60] loss: 1.195513
[19,    70] loss: 1.148147
[19,    80] loss: 1.113787
[19,    90] loss: 1.170788
[19,   100] loss: 1.233131
[19,   110] loss: 1.210635
[19,   120] loss: 1.106129
[19,   130] loss: 1.093558
[19,   140] loss: 1.219643
[19,   150] loss: 1.104943
[19,   160] loss: 1.262863
[19,   170] loss: 1.137697
[19,   180] loss: 1.187616
[19,   190] loss: 1.179015
[19,   200] loss: 1.253501
[19,   210] loss: 1.301903
[19,   220] loss: 1.232333
[19,   230] loss: 1.197571
[19,   240] loss: 1.223953
[19,   250] loss: 1.236911
[19,   260] loss: 1.374642
[19,   270] loss: 1.233690
[19,   280] loss: 1.178967
[19,   290] loss: 1.314918
val loss: 1.599219653322281
best loss: 1.589790438975159
Patience: 14
time: 1619.2750451564789
[20,    10] loss: 1.106786
[20,    20] loss: 1.155239
[20,    30] loss: 1.075504
[20,    40] loss: 1.116196
[20,    50] loss: 1.167159
[20,    60] loss: 1.156141
[20,    70] loss: 1.221261
[20,    80] loss: 1.186505
[20,    90] loss: 1.116672
[20,   100] loss: 1.122396
[20,   110] loss: 1.234786
[20,   120] loss: 1.270949
[20,   130] loss: 1.205060
[20,   140] loss: 1.057501
[20,   150] loss: 1.183265
[20,   160] loss: 1.092371
[20,   170] loss: 1.133588
[20,   180] loss: 1.174463
[20,   190] loss: 1.179763
[20,   200] loss: 1.260221
[20,   210] loss: 1.154460
[20,   220] loss: 1.168433
[20,   230] loss: 1.219239
[20,   240] loss: 1.238808
[20,   250] loss: 1.219253
[20,   260] loss: 1.176892
[20,   270] loss: 1.252670
[20,   280] loss: 1.227727
[20,   290] loss: 1.229958
val loss: 1.6050717668021193
best loss: 1.589790438975159
Patience: 13
time: 1704.4304625988007
[21,    10] loss: 1.123743
[21,    20] loss: 1.176680
[21,    30] loss: 1.269410
[21,    40] loss: 1.067086
[21,    50] loss: 1.130329
[21,    60] loss: 1.120867
[21,    70] loss: 1.097022
[21,    80] loss: 1.182125
[21,    90] loss: 1.193841
[21,   100] loss: 1.143317
[21,   110] loss: 1.185925
[21,   120] loss: 1.086562
[21,   130] loss: 1.185811
[21,   140] loss: 1.212352
[21,   150] loss: 1.079047
[21,   160] loss: 1.138970
[21,   170] loss: 1.176382
[21,   180] loss: 1.127449
[21,   190] loss: 1.160651
[21,   200] loss: 1.130143
[21,   210] loss: 1.237860
[21,   220] loss: 1.187005
[21,   230] loss: 1.208589
[21,   240] loss: 1.077719
[21,   250] loss: 1.123425
[21,   260] loss: 1.219608
[21,   270] loss: 1.092416
[21,   280] loss: 1.152290
[21,   290] loss: 1.148991
val loss: 1.6138174041319886
best loss: 1.589790438975159
Patience: 12
time: 1789.8159308433533
[22,    10] loss: 1.085832
[22,    20] loss: 1.132084
[22,    30] loss: 1.098815
[22,    40] loss: 1.211782
[22,    50] loss: 1.073081
[22,    60] loss: 1.155842
[22,    70] loss: 1.122879
[22,    80] loss: 1.188050
[22,    90] loss: 1.129905
[22,   100] loss: 1.116052
[22,   110] loss: 1.108079
[22,   120] loss: 1.133470
[22,   130] loss: 1.111046
[22,   140] loss: 1.136854
[22,   150] loss: 1.086724
[22,   160] loss: 1.189114
[22,   170] loss: 1.205482
[22,   180] loss: 1.127474
[22,   190] loss: 1.055561
[22,   200] loss: 1.180144
[22,   210] loss: 1.121920
[22,   220] loss: 1.125471
[22,   230] loss: 1.104679
[22,   240] loss: 1.085948
[22,   250] loss: 1.137820
[22,   260] loss: 1.119427
[22,   270] loss: 1.143019
[22,   280] loss: 1.107063
[22,   290] loss: 1.165381
val loss: 1.630611325556031
best loss: 1.589790438975159
Patience: 11
time: 1875.132746219635
[23,    10] loss: 1.123292
[23,    20] loss: 1.036251
[23,    30] loss: 1.068388
[23,    40] loss: 1.071917
[23,    50] loss: 1.104495
[23,    60] loss: 1.113127
[23,    70] loss: 1.077585
[23,    80] loss: 1.140286
[23,    90] loss: 1.165961
[23,   100] loss: 1.029578
[23,   110] loss: 1.128899
[23,   120] loss: 1.038325
[23,   130] loss: 1.093649
[23,   140] loss: 1.089190
[23,   150] loss: 1.059765
[23,   160] loss: 1.141822
[23,   170] loss: 1.088416
[23,   180] loss: 1.080059
[23,   190] loss: 1.135663
[23,   200] loss: 1.071857
[23,   210] loss: 1.117935
[23,   220] loss: 1.157845
[23,   230] loss: 1.127156
[23,   240] loss: 1.128773
[23,   250] loss: 1.142664
[23,   260] loss: 1.117391
[23,   270] loss: 1.068246
[23,   280] loss: 1.014209
[23,   290] loss: 1.136824
val loss: 1.6364582691091123
best loss: 1.589790438975159
Patience: 10
time: 1960.3918859958649
[24,    10] loss: 1.137985
[24,    20] loss: 1.003177
[24,    30] loss: 1.090674
[24,    40] loss: 0.992990
[24,    50] loss: 1.035515
[24,    60] loss: 1.068475
[24,    70] loss: 1.017926
[24,    80] loss: 1.087817
[24,    90] loss: 1.027228
[24,   100] loss: 1.085180
[24,   110] loss: 1.067472
[24,   120] loss: 1.003418
[24,   130] loss: 1.081602
[24,   140] loss: 1.189763
[24,   150] loss: 1.068000
[24,   160] loss: 1.058767
[24,   170] loss: 1.008056
[24,   180] loss: 1.071327
[24,   190] loss: 1.106035
[24,   200] loss: 1.101201
[24,   210] loss: 1.034806
[24,   220] loss: 1.063959
[24,   230] loss: 1.152475
[24,   240] loss: 1.042651
[24,   250] loss: 1.129074
[24,   260] loss: 1.180469
[24,   270] loss: 1.092102
[24,   280] loss: 1.098634
[24,   290] loss: 1.090951
val loss: 1.6549023420767253
best loss: 1.589790438975159
Patience: 9
time: 2045.6351509094238
[25,    10] loss: 0.989013
[25,    20] loss: 1.003568
[25,    30] loss: 0.898692
[25,    40] loss: 1.073519
[25,    50] loss: 1.100449
[25,    60] loss: 1.004018
[25,    70] loss: 1.065747
[25,    80] loss: 1.058852
[25,    90] loss: 0.923858
[25,   100] loss: 1.009507
[25,   110] loss: 1.134567
[25,   120] loss: 1.102170
[25,   130] loss: 1.062170
[25,   140] loss: 1.008458
[25,   150] loss: 1.041103
[25,   160] loss: 1.072224
[25,   170] loss: 0.966972
[25,   180] loss: 1.028231
[25,   190] loss: 1.049358
[25,   200] loss: 1.109695
[25,   210] loss: 1.112710
[25,   220] loss: 1.076569
[25,   230] loss: 1.052404
[25,   240] loss: 1.086738
[25,   250] loss: 1.089339
[25,   260] loss: 1.013312
[25,   270] loss: 1.099836
[25,   280] loss: 1.160257
[25,   290] loss: 1.131394
val loss: 1.6455705947519175
best loss: 1.589790438975159
Patience: 8
time: 2130.821836948395
[26,    10] loss: 1.012817
[26,    20] loss: 0.998636
[26,    30] loss: 1.023648
[26,    40] loss: 1.022599
[26,    50] loss: 1.036809
[26,    60] loss: 1.000084
[26,    70] loss: 1.064345
[26,    80] loss: 1.043051
[26,    90] loss: 1.104738
[26,   100] loss: 1.043871
[26,   110] loss: 1.038905
[26,   120] loss: 1.016746
[26,   130] loss: 1.019630
[26,   140] loss: 1.004089
[26,   150] loss: 0.995349
[26,   160] loss: 1.058322
[26,   170] loss: 0.988305
[26,   180] loss: 0.979596
[26,   190] loss: 1.088066
[26,   200] loss: 1.025136
[26,   210] loss: 0.974406
[26,   220] loss: 1.079261
[26,   230] loss: 0.964765
[26,   240] loss: 1.120422
[26,   250] loss: 1.008207
[26,   260] loss: 1.107096
[26,   270] loss: 1.021954
[26,   280] loss: 1.027329
[26,   290] loss: 0.976384
val loss: 1.6625230060510339
best loss: 1.589790438975159
Patience: 7
time: 2216.040909051895
[27,    10] loss: 0.954952
[27,    20] loss: 0.982666
[27,    30] loss: 0.969022
[27,    40] loss: 1.015102
[27,    50] loss: 0.946814
[27,    60] loss: 1.026633
[27,    70] loss: 1.069772
[27,    80] loss: 1.024048
[27,    90] loss: 0.976389
[27,   100] loss: 1.044940
[27,   110] loss: 1.077386
[27,   120] loss: 0.986683
[27,   130] loss: 1.007966
[27,   140] loss: 1.090963
[27,   150] loss: 0.948183
[27,   160] loss: 0.961011
[27,   170] loss: 1.006139
[27,   180] loss: 0.970258
[27,   190] loss: 1.066976
[27,   200] loss: 1.082590
[27,   210] loss: 1.002587
[27,   220] loss: 0.983381
[27,   230] loss: 0.971833
[27,   240] loss: 0.988547
[27,   250] loss: 0.993788
[27,   260] loss: 1.114955
[27,   270] loss: 0.975574
[27,   280] loss: 1.072572
[27,   290] loss: 1.006565
val loss: 1.6745594789320144
best loss: 1.589790438975159
Patience: 6
time: 2301.142290830612
[28,    10] loss: 0.993633
[28,    20] loss: 0.933888
[28,    30] loss: 0.938073
[28,    40] loss: 1.003987
[28,    50] loss: 1.002321
[28,    60] loss: 1.051816
[28,    70] loss: 0.938931
[28,    80] loss: 1.013170
[28,    90] loss: 1.066844
[28,   100] loss: 0.987103
[28,   110] loss: 1.022065
[28,   120] loss: 0.987810
[28,   130] loss: 1.018536
[28,   140] loss: 1.069301
[28,   150] loss: 1.008269
[28,   160] loss: 1.027122
[28,   170] loss: 0.951164
[28,   180] loss: 0.993562
[28,   190] loss: 0.982054
[28,   200] loss: 0.903312
[28,   210] loss: 1.023947
[28,   220] loss: 0.934121
[28,   230] loss: 1.080795
[28,   240] loss: 1.010885
[28,   250] loss: 1.003850
[28,   260] loss: 1.013767
[28,   270] loss: 0.933426
[28,   280] loss: 0.974049
[28,   290] loss: 1.037223
val loss: 1.6863246709180444
best loss: 1.589790438975159
Patience: 5
time: 2386.1511561870575
[29,    10] loss: 0.943745
[29,    20] loss: 0.954998
[29,    30] loss: 0.981272
[29,    40] loss: 0.885751
[29,    50] loss: 0.924693
[29,    60] loss: 0.966431
[29,    70] loss: 0.899993
[29,    80] loss: 0.901279
[29,    90] loss: 0.967720
[29,   100] loss: 0.922369
[29,   110] loss: 0.921479
[29,   120] loss: 0.933386
[29,   130] loss: 1.008695
[29,   140] loss: 1.065956
[29,   150] loss: 1.028979
[29,   160] loss: 1.023254
[29,   170] loss: 1.068251
[29,   180] loss: 0.948972
[29,   190] loss: 0.976790
[29,   200] loss: 0.921547
[29,   210] loss: 0.971868
[29,   220] loss: 1.069956
[29,   230] loss: 0.967251
[29,   240] loss: 0.919211
[29,   250] loss: 1.025727
[29,   260] loss: 0.943526
[29,   270] loss: 0.985263
[29,   280] loss: 1.039593
[29,   290] loss: 1.005459
val loss: 1.6984525858019843
best loss: 1.589790438975159
Patience: 4
time: 2471.237168073654
[30,    10] loss: 0.944803
[30,    20] loss: 1.035707
[30,    30] loss: 0.955617
[30,    40] loss: 0.910346
[30,    50] loss: 0.952237
[30,    60] loss: 0.888029
[30,    70] loss: 0.925236
[30,    80] loss: 0.942618
[30,    90] loss: 0.968800
[30,   100] loss: 0.981751
[30,   110] loss: 0.871099
[30,   120] loss: 0.904274
[30,   130] loss: 0.896767
[30,   140] loss: 0.943473
[30,   150] loss: 0.952474
[30,   160] loss: 1.009122
[30,   170] loss: 0.921365
[30,   180] loss: 0.957335
[30,   190] loss: 1.049704
[30,   200] loss: 0.971722
[30,   210] loss: 0.971017
[30,   220] loss: 0.964544
[30,   230] loss: 0.896122
[30,   240] loss: 0.936604
[30,   250] loss: 0.933567
[30,   260] loss: 1.025045
[30,   270] loss: 0.939040
[30,   280] loss: 0.960795
[30,   290] loss: 0.970698
val loss: 1.700757442991727
best loss: 1.589790438975159
Patience: 3
time: 2556.1133263111115
[31,    10] loss: 0.953129
[31,    20] loss: 0.864302
[31,    30] loss: 0.944725
[31,    40] loss: 0.967326
[31,    50] loss: 0.896329
[31,    60] loss: 0.867234
[31,    70] loss: 0.947121
[31,    80] loss: 0.912221
[31,    90] loss: 0.909514
[31,   100] loss: 0.989159
[31,   110] loss: 1.027036
[31,   120] loss: 0.905676
[31,   130] loss: 0.966753
[31,   140] loss: 0.924077
[31,   150] loss: 0.964552
[31,   160] loss: 0.914331
[31,   170] loss: 0.915158
[31,   180] loss: 1.004941
[31,   190] loss: 0.964434
[31,   200] loss: 1.037953
[31,   210] loss: 0.882206
[31,   220] loss: 0.913251
[31,   230] loss: 0.899751
[31,   240] loss: 0.966348
[31,   250] loss: 0.939607
[31,   260] loss: 0.981451
[31,   270] loss: 0.850440
[31,   280] loss: 0.924687
[31,   290] loss: 0.926078
val loss: 1.7152013288084835
best loss: 1.589790438975159
Patience: 2
time: 2641.086818218231
[32,    10] loss: 0.915378
[32,    20] loss: 0.942317
[32,    30] loss: 0.889581
[32,    40] loss: 0.935111
[32,    50] loss: 0.940597
[32,    60] loss: 0.841636
[32,    70] loss: 0.840174
[32,    80] loss: 0.879177
[32,    90] loss: 0.797725
[32,   100] loss: 0.925884
[32,   110] loss: 0.959103
[32,   120] loss: 0.926111
[32,   130] loss: 0.942959
[32,   140] loss: 0.933087
[32,   150] loss: 0.937754
[32,   160] loss: 0.890334
[32,   170] loss: 0.963797
[32,   180] loss: 0.979776
[32,   190] loss: 0.924802
[32,   200] loss: 0.995706
[32,   210] loss: 0.870460
[32,   220] loss: 0.964110
[32,   230] loss: 0.877810
[32,   240] loss: 0.936861
[32,   250] loss: 0.885178
[32,   260] loss: 0.955365
[32,   270] loss: 0.900187
[32,   280] loss: 0.961299
[32,   290] loss: 0.933691
val loss: 1.725101888650772
best loss: 1.589790438975159
Patience: 1
time: 2726.1044459342957
Early stop: True
Replacing with better model
